%!TEX root = ../main.tex
\documentclass[../main]{subfiles}

\begin{document}

\newpage
\section{Анализ предметной области}

Работы по проблеме, решаемой в выпускной квалификационной работе, можно разделить на три группы. Первая группа -- работы, связанные с анализом рисков конфиденциальности. Вторая группа работ связана с анализом политик, представленных на естественном языке, и их дальнейшим представлением в удобной форме. Для этого используются методы обработки естественного языка (NLP). Третья группа работ посвящена разработке единого стандарта политик конфиденциальности и их автоматизированной генерации. Для этого используются методы разработки формальных языков.

Эти три группы взаимосвязаны с точки зрения формализации политик безопасности. Сначала тексты политики конфиденциальности, представленные на естественном языке, обрабатываются для формального определения политик конфиденциальности (с использованием некоторого формального языка), наконец, политики конфиденциальности, указанные на формальном языке, могут быть применены для расчета рисков конфиденциальности.

\subsection{Сравнительный анализ актуальных работ}
Анализ текстов политик конфиденциальности, представленных на естественном языке, рассматривается в статьях \cite{MDPI5}, \cite{MDPI6}, \cite{MDPI9}.

В работе \cite{MDPI5} описан подход к автоматизированному извлечению и анализу политик конфиденциальности для приложений Android. Авторы используют подход TF-IDF для построения вектора признаков текста политик и классификатор на основе машины опорных векторов для обнаружения различных методов обработки данных, таких как контактный адрес электронной почты, контактный номер телефона, местоположение GPS или Wi-Fi и т.д. Для обучения моделей авторы создали аннотированный корпус политик конфиденциальности APP-350.

В статье \cite{MDPI6} описана семантическая структура PrivOnto для анализа политик конфиденциальности. PrivOnto использует в качестве входных данных набор аннотированных политик конфиденциальности и разработанную общую онтологию. Предлагаемая онтология представляет собой набор политик с определенными практиками в отношении данных с учетом их конфиденциальности. Эксперты проанализировали набор политик конфиденциальности и вручную аннотировали их, используя 11 выделенных категорий методов обработки данных: <<First-party Collection/Use>>, <<Third-party Sharing/Col\-lection>>, <<User Choice/Control>>, <<User Access/Edition/Deletion>>, <<Data Retention>>, <<Data Security>>, <<Policy Change>>, <<Do Not Track>>, <<International and Special Audience>> и другие. Исследователи аннотировали более 23000 практик обработки данных, извлеченных из 115 политик конфиденциальности. Затем аннотированный набор использовался для обучения классификатора для автоматизированного аннотирования. Авторы использовали краудсорсинг, машинное обучение и обработку естественного языка для автоматизированного аннотирования политик конфиденциальности и создания онтологий. Это исследование предлагает один из самых эффективных подходов, однако авторы данной работы не уделяют внимания оценке рисков.

Онтологический подход к представлению политики конфиденциальности также предлагается в статьях \cite{MDPI7}, \cite{MDPI8}. В работе \cite{MDPI7} авторы разработали онтологию конфиденциальности PrOnto для проверки соответствия политики GDPR, однако они генерируют онтологию вручную. В работе \cite{MDPI8} предлагается подход, основанный на построении онтологии с использованием вопросов компетенции.

В работе \cite{MDPI9} описывается подход к автоматическому обнаружению вариантов отказа от некоторых способов сбора и использования личных данных в текстах политик конфиденциальности на основе машинного обучения. Авторы \cite{MDPI9} протестировали различные методы машинного обучения для анализа текста политик, такие как линейная регрессия и нейронные сети. Ограничение подхода состоит в том, что для его применения требуется размеченный набор данных. Авторы реализовали разметку вручную. В статье \cite{MDPI10} также рассматривается автоматическое обнаружение вариантов отказа в текстах политик конфиденциальности. Авторы используют набор данных из статьи \cite{MDPI6} для обучения своих моделей.

Разработка формальных языков для автоматизированной генерации и единой спецификации политик конфиденциальности рассматривается в статьях \cite{MDPI11}--\cite{MDPI15}. Формальный язык состоит из языкового алфавита и правил построения последовательностей с использованием символов алфавита, то есть языковой грамматики. Текст, указанный на таком языке, можно обработать математическими методами.

В статье \cite{MDPI11} предлагается платформа для корпоративных практик конфиденциальности E-P3P, чтобы формализовать политику конфиденциальности на машиночитаемом языке. Этот язык может быть применен на предприятии. Формализованная политика определяет, какие типы личной информации PII, для каких целей и какими пользователями в организации могут быть использованы. Машиночитаемый язык включает терминологию и набор правил авторизации. Терминология включает категории данных, цели, пользователей данных, набор действий, набор обязательств и набор условий. Правила авторизации используются, чтобы разрешить или запретить действие. Аналогичный подход к управлению авторизацией и контролю доступа представлен в работе \cite{MDPI12}. Предлагаемая модель состоит из пользователей/групп, используемых данных, целей доступа и режимов доступа. Он используется для обеспечения того, чтобы личная информация использовалась только для авторизации. Авторы \cite{MDPI12} также предложили язык конфиденциальности, основанный на упомянутой модели. Этот язык используется для формализации правил конфиденциальности, контроля доступа и автоматического применения этих правил с помощью системы контроля доступа. Предлагаемая модель ограничивается только контролем доступа с учетом аспектов конфиденциальности.

В публикации \cite{MDPI13} так же используется подход, основанный на языковых методах. Авторы \cite{MDPI13} рассматривают принцип конфиденциальности, который гласит, что личные данные пользователя не могут использоваться для целей, отличных от той, для которой они были собраны, без согласия субъекта данных. Авторы \cite{MDPI13} предполагают, что в большинстве случаев пользователи не имеют представления о том, как и для каких целей используется их личная информация. Чтобы решить эту проблему, авторы предлагают политику обработки данных DHP \cite{MDPI13}, показывающую пользователям, кто и на каких условиях может обрабатывать их личные данные. Эта политика может быть разработана поставщиком услуг или пользователем с использованием языка DHP. Язык включает набор условий и правил, а именно: получателей, действия, цели, PII, условия, положения и обязательства. Затем DHP применяется в точках принятия решения по политике (принятие решения в отношении запроса доступа) и точек реализации политики (реализация решения) системы управления доступом. Минус в том, что такую ​​политику нужно разрабатывать для каждого нового продукта.

В статье \cite{MDPI14} предлагается язык PILOT для спецификации политики конфиденциальности. Авторы также разработали инструмент, позволяющий оценивать риски, связанные с конфиденциальностью, если политика определяется с использованием предложенного языка. Преимущество подхода в том, что он позволяет оценивать риски. Недостатком является то, что такой подход не позволяет оценивать их автоматически, если политика не задана на разработанном формальном языке. Авторы предлагают пользователям самим определять политики конфиденциальности, а затем представляют оценку рисков политики.

В работе \cite{MDPI15} предлагается многоуровневый язык конфиденциальности LPL \cite{MDPI15}, который удовлетворяет следующим требованиям: различие между источником и получателем данных, создание политик конфиденциальности с учетом целей, операций с данными, гарантия удобочитаемости на основе многоуровневых политик конфиденциальности. К недостаткам этой работы можно отнести: исследование не завершено, и предлагаемая формулировка сейчас не охватывает все аспекты конфиденциальности; компания должна определить свою политику конфиденциальности, используя LPL, прежде чем анализировать ее. Оценка рисков конфиденциальности, заданная с использованием формального языка PILOT, рассматривается в \cite{MDPI14}.

Отдельно следует отметить подходы, позволяющие рассчитывать риски конфиденциальности с учетом операций с персональными данными в анализируемой системе. Эти подходы не основаны непосредственно на политике конфиденциальности, но относятся к исследованиям в области оценки рисков конфиденциальности.

Специалисты института NIST предложили методологию оценки рисков конфиденциальности PRAM \cite{MDPI16}, которая основана на ручной идентификации требований конфиденциальности к анализируемой системе и связанных с ними рисков конфиденциальности. Методология оценки включает оценку вероятности (по шкале от 0 до 10) и воздействия (с точки зрения различных затрат, которые следует суммировать) каждого риска, а затем расчет (как произведение воздействия и вероятности) и определение приоритетности рисков.

В публикации \cite{MDPI17} предлагается подход к оценке рисков конфиденциальности, основанный на деревьях угроз. Деревья построены на основе информации о системе, личных данных, соответствующих источниках риска, соответствующих событиях и их влиянии на конфиденциальность. Узлы дерева угроз представлены в виде троек, включающих персональные данные, компонент системы и источник риска. Корневой узел дерева угроз соответствует нарушению конфиденциальности. Листовые узлы соответствуют использованию данных наиболее вероятным источником риска. Настройки конфиденциальности пользователей также учитываются при расчете вероятности нарушения конфиденциальности.

Результаты анализа рассмотренных работ представлены в таблице \ref{tab:table1}. Хотя существует множество исследований, посвященных анализу конфиденциальности и относящихся к трем упомянутым группам, нет комплексного исследования, охватывающего все три группы из анализа представленных политик конфиденциальности.

Стоит отдельно упомянуть работу \cite{P2Onto}, в которой авторы рассматривают проблему расчета рисков конфиденциальности на основе анализа политик конфиденциальности, решение которой позволит пользователям и организациям понять, какое влияние на конфиденциальность эти политики могут оказать. Авторы предлагают подход, который включает в себя сначала анализ текста политики конфиденциальности, представленной на естественном языке, генерацию и автоматическую обработку онтологии для каждой политики, указанной на естественном языке с использованием NLP, и окончательный расчет рисков конфиденциальности с использованием сгенерированных онтологий.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
\begin{longtable}[H]{|M{.3\x}|M{.3\x}|M{.2\x}|M{.2\x}|}

    \caption{Сравнительный анализ работ\label{tab:table1}} \\\hline
    \multicolumn{1}{|H{.3\x}|}{Описание аспектов конфиденциальности из политики конфиденциальности}
    & \multicolumn{1}{H{.3\x}|}{Формализация политики конфиденциальности} 
    & \multicolumn{1}{H{.2\x}|}{Оценка риска для персональных данных} 
    & \multicolumn{1}{H{.2\x}|}{Генерация онтологий} \\\hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:table1}}\\\hline
    \multicolumn{1}{|H{.3\x}|}{Описание аспектов конфиденциальности из политики конфиденциальности}
    & \multicolumn{1}{H{.3\x}|}{Формализация политики конфиденциальности} 
    & \multicolumn{1}{H{.2\x}|}{Оценка риска для персональных данных} 
    & \multicolumn{1}{H{.2\x}|}{Генерация онтологий}\\\hline
    \endhead
    \endfoot
    \endlastfoot

    - NLP: TF-IDF для построения вектора признаков; SVC для обнаружения практики конфиденциальности.\newline
    - Аннотированный корпус политик конфиденциальности APP-350.\newline
    - Ограничено приложениями для Android. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    - Краудсорсинг, ML, NLP.\newline
    - Автоматическая аннотация политик конфиденциальности.\newline
    - 115 аннотированных политик конфиденциальности.\newline
    & Создание онтологии для формального представления политик.
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{+}\\
    
    \hline

    - Текст анализируется и онтология генерируется вручную.\newline
    - Позволяет проверить соответствие политики GDPR. 
    & Онтология
    & \multicolumn{1}{c|}{--} & Онтология PrOnto\\
    
    \hline

    Построение онтологии политики конфиденциальности на основе ручной обработки текста. 
    & Онтология
    & \multicolumn{1}{c|}{--} & 
    - Онтология генерируется вручную.\newline
    - Подход основан на вопросах компетенции.\\
    
    \hline

    - ML: линейная регрессия и нейронные сети.\newline
    - Автоматическое определение вариантов отказа.\newline
    - Требуется маркированный набор данных. Авторы разметили набор данных вручную. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    - NLP, модели включения фраз и модели машинного обучения (логистическая регрессия, линейная SVM, random forest, наивный байесовский алгоритм и ближайший сосед).\newline
        - Автоматическое определение вариантов отказа от сбора.\newline
        - Требуется маркированный набор данных. Авторы использовали набор данных из  \cite{MDPI7}.
    & \multicolumn{1}{c|}{--}
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & - Машиночитаемый язык, включающий терминологию и набор правил авторизации (действия разрешить и запретить).\newline
    - Позволяет формализовать политику, чтобы указать, какие типы PII, для каких целей и для каких пользователей могут использоваться. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & - Язык конфиденциальности, основанный на модели, включающей пользователей/группы, данные, к которым осуществляется доступ, цели доступа и режимы доступа.\newline
    - Позволяет формализовать правила контроля доступа и автоматизировать выполнение этих правил. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & - Подход, основанный на языке DHP. Язык включает набор терминов и правил.\newline
    - Позволяет показать пользователям, кто и на каких условиях может обрабатывать их личные данные, принимать и реализовывать решения относительно запроса доступа.\newline
    - Политика должна разрабатываться для каждого нового продукта. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & Подход на основе языка PILOT. 
    & Позволяет оценить риски, связанные с конфиденциальностью, если политика указана с помощью PILOT. 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & - Подход, основанный на LPL.\newline
    - Позволяет различать источник и получателя данных.\newline
    - Позволяет формировать политики конфиденциальности с учетом целей работы с данными.\newline
    - Гарантирует удобочитаемость многоуровневых политик конфиденциальности.\newline
    - Предлагаемая формулировка не охватывает все аспекты конфиденциальности. 
    & \multicolumn{1}{c|}{--} 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & \multicolumn{1}{c|}{--} 
    & Качественная оценка на основе анкет.\newline
    Непосредственно к политике конфиденциальности не применяется.
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    \multicolumn{1}{|c|}{--} 
    & \multicolumn{1}{c|}{--} 
    & - Основан на деревьях угроз. \newline
    - Деревья угроз формируются вручную. 
    & \multicolumn{1}{c|}{--}\\
    
    \hline

    Использование NLP для извлечения аспектов использования данных. 
    & Онтология
    & Автоматический расчет рисков конфиденциальности на основе онтологии. 
    & Онтология P2Onto\\
    
    \hline

\end{longtable}
\end{ltwrap}

Авторы \cite{P2Onto} на основе предыдущих работ предложили подход, который применим для формализации и оценки угроз персональным данным. Стоит отметить, что данный подход был протестирован авторами вручную на нескольких политиках безопасности и дал определенный результат. В связи с этим данный подход был выбран в качестве базового для построения системы формализации политик безопасности.

\subsection{Онтологическое представление политик безопасности}

Входными данными для предлагаемой процедуры оценки рисков конфиденциальности является политика конфиденциальности, доступная конечному пользователю службы или устройства. Поскольку в большинстве случаев эти документы содержат информацию об использовании персональных данных в неструктурированной форме, необходимо создать формальное описание данных, представленных в тексте, для применения любых дальнейших процедур оценки. Авторы \cite{P2Onto} предлагают использовать онтологию в качестве формального представления действий по обработке политик и их особенностей, необходимых для выполнения оценки риска. Выбор формализации на основе онтологий объясняется возможностью определения основных понятий, сущностей, их свойств и семантических отношений между ними как для человека, так и для машинного чтения и многократного использования. Таким образом, предлагаемый авторами подход включает следующие шаги: 
\begin{enumerate}
    \item создание базовой многоразовой онтологии P2Onto, которая описывает основные аспекты сценариев использования персональных данных и служит основой для установления процедур расчета рисков;
    \item отображение текста политики конфиденциальности в базовую онтологию P2Onto;
    \item расчет оценки риска на основе сгенерированного онтологического представления и алгоритмов, указанных для онтологии P2Onto.
\end{enumerate}

Таким образом, ключевым элементом предлагаемого подхода является онтология P2Onto, которая описывает различные аспекты обработки персональных данных, такие как <<First-party Collection/Use>>, <<Third-party Collection/Sharing>> и другие, и обеспечивает формальную основу для процедуры оценки рисков, и, которая также учитывает концепции и категории при вычислении оценки риска. На рисунке \ref{fig:figure1} представлен порядок оценки рисков, предложенный авторами \cite{P2Onto}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Общая схема процедуры оценки риска\label{fig:figure1}}}
    {\includegraphics[width=.8\textwidth]{figure1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Онтология P2Onto призвана обеспечить формальную основу для процедуры оценки риска и может использоваться для проверки и объяснения полученных оценок риска. В ней описываются различные аспекты обработки персональных данных, участвующие в процессе субъекты и устанавливаются семантические отношения. Согласно процессу проектирования онтологий на основе политик конфиденциальности, предложенному в \cite{MDPI8}, построение онтологии требует сначала идентификации основных сценариев использования персональных данных и установления их характеристик, соответствующих задаче анализа. На рисунке \ref{fig:figure2} показана схема потока проектирования онтологии P2Onto. 

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{P2Onto процесс проектирования онтологии\label{fig:figure2}}}
    {\includegraphics[width=.8\textwidth]{figure2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Авторы \cite{P2Onto} применяют сценарии и аспекты использования персональных данных, определенные экспертами в предметной области, которые проанализировали существующие политики конфиденциальности и соответствующие правовые нормы и требования, такие как COPPA \cite{MDPI2} и правила конфиденциальности HIPAA \cite{MDPI3}, широко используемые в исследованиях \cite{MDPI6}, \cite{MDPI8} и \cite{MDPI18}:
\begin{itemize}
    \item <<First-party Collection/Use>> -- характеризует, какие личные данные собирает поставщик услуг, управляя устройством, веб-сайтом или приложением, как они собираются, каковы правовые основания и цели сбора данных.
    \item <<Third-party Collection/Sharing>> -- характеризует все вопросы, касающиеся процедур обмена данными, включая форму обмена данными -- агрегированные, анонимные или необработанные.
    \item <<Data Security>> -- описывает механизмы безопасности, как технические, так и организационные, используемые для защиты данных.
    \item <<Data Retention>> -- характеризует временные рамки обработки и хранения персональных данных.
    \item <<Data Aggregation>> -- определяет, собирает ли поставщик услуг личные данные.
    \item <<Privacy Settings>> -- определяет доступные инструменты и варианты для конечного пользователя, чтобы ограничить объем собираемых персональных данных (вопросы согласия/отказа при сборе персональных данных).
    \item <<User Choice/Control>> -- определяет инструменты и механизмы, предоставляемые пользователю для манипулирования личными данными -- доступ, редактирование и удаление.
    \item <<Breach Notification>> -- определяет инструменты и механизмы, которые поставщик услуг использует для информирования о нарушении конфиденциальности личных данных.
    \item <<Policy Change>> -- определяет, какие инструменты и механизмы использует поставщик услуг для информирования конечного пользователя об изменениях в политике конфиденциальности и возможных реакциях, доступных конечному пользователю.
    \item <<Do Not Track>> -- описывает, как обрабатываются сигнал <<не отслеживать>>.
    \item <<International and Specific Audience>> -- описывает различные вопросы, связанные с обработкой персональных данных особой аудитории, такой как дети, и граждане определенных государств и регионов.
\end{itemize}

Благодаря анализу этих сценариев использования персональных данных и их аспектов конфиденциальности, авторами было выделено четыре общих класса -- данные, действия, агент и механизм, которые образуют основу для описания сценариев использования персональных данных, остальные классы используются для определения их свойств.

Данные -- это суперкласс, который используется для определения категорий личных и неличных данных. Авторы следуют определению GDPR, чтобы указать типы персональных данных, которые описываются как <<любая информация, относящаяся к идентифицированному или идентифицируемому физическому лицу (субъекту данных); идентифицируемое физическое лицо -- это лицо, которое может быть идентифицировано прямо или косвенно, в частности, посредством ссылки на идентификатор, такой как имя, идентификационный номер, данные о местоположении, онлайн-идентификатор или один или несколько факторов, специфичных для физической, физиологической, генетической, ментальной, экономической, культурной или социальной идентичности человека>> \cite{GDPR}, \cite{MDPI4}. Это позволило определить такие подклассы персональных данных, как <<User\_Account\_Data>>, включающие информацию о входе в систему, аватар пользователя, электронную почту, физический адрес, <<User\_Device\_Info>> и <<User\_App\_Info>>, содержащие данные о пользовательском устройстве и приложениях, такие как версия, модель, время обновления и т.д. Также авторы обрисовали в общих чертах <<Tracking\_Data>>, чтобы указать данные, которые могут использоваться для отслеживания пользователя, такие как IP-адрес, файлы cookie, отпечаток браузера, чтобы иметь возможность оценить риски для сценария <<Do Not Track>>, и представили подкласс <<Service\_Data>>, который используется для указания конкретных данных об обслуживании и работе устройства, например, блокировке и разблокировке, яркости экрана и т.д., которые могут использоваться для определения привычек и стиля жизни пользователя. Подробная иерархия классов данных, включая иерархию конфиденциальных данных, показана на рисунке \ref{fig:figure3}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Иерархия классов данных\label{fig:figure3}}}
    {\includegraphics[width=.8\textwidth]{figure3.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Следует отметить, что класс <<Non\_Personal\_Data>> используется для описания неличных данных, возникающих при получении персональных данных посредством анонимизации или агрегации персональных данных. Знание того, сколько типов данных -- идентифицируемых и нет -- собираются о конкретном пользователе устройства, имеет важное значение в процедуре оценки рисков.

Как следует из списка аспектов конфиденциальности использования персональных данных, некоторые аспекты напрямую связаны с обработкой данных, например сбор, обработка, совместное использование, хранение или безопасность данных, в то время как другие относятся к деятельности, которая косвенно связана с обработкой данных, например уведомления в случае изменения политики или нарушения данных, предоставление доступа, прав редактирования, удаления и т.д. По этой причине авторами были выделены два разных подкласса класса активности -- <<Data\_Activity>> и <<Control\_Activity>>. На рисунке \ref{fig:figure4} показана иерархия подклассов <<Activity>>. 

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Иерархия классов активности\label{fig:figure4}}}
    {\includegraphics[width=.8\textwidth]{figure4.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Класс <<Data\_Activity>> -- это общий класс для определения различных типов операций по обработке данных. Несмотря на то, что эти действия имеют свои отличительные характеристики, можно выделить общие черты, такие как цель операций с данными, формат обрабатываемых данных -- анонимные или необработанные, правовая основа для обработки данных и контролирующие лица. На рисунке \ref{fig:figure5} показаны наиболее важные классы, относящиеся к деятельности по обработке данных. Цель обработки данных является важной концепцией при оценке рисков конфиденциальности, и авторы выделили следующие цели обработки данных: предоставление услуг, реклама и маркетинг, аналитика и исследования, персонализация, безопасность, слияние и поглощение, соответствие законодательству, другое и <<не определено>>. Каждый из них представляет собой отдельный подкласс.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Контекст Data\_Activity\label{fig:figure5}}}
    {\includegraphics[width=.8\textwidth]{figure5.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Чтобы указать владельца данных, обработчика данных, а также других третьих сторон, участвующих в обработке данных, используется класс <<Agent>>, изображенный на рисунке \ref{fig:figure6}. Авторы предлагают повторно использовать эту концепцию из онтологии PROV-O, которая определяет концепт <<Agent>> как субъект, который несет некоторую форму ответственности за происходящую деятельность, за наличие сущности или за деятельность другого агента \cite{MDPI22}. Эта концепция позволяет указать случаи, когда данные собираются от третьих сторон, таких как социальные сети, общедоступные источники с открытым исходным кодом. Класс <<Agent>> также используется для выявления случаев, когда данные собираются от посторонних лиц, то есть людей, которые не владеют устройством или услугой и с большой вероятностью не дают согласия на обработку данных. 

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Иерархия классов агентов\label{fig:figure6}}}
    {\includegraphics[width=.8\textwidth]{figure6.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Класс <<Mechanism>> -- это общий класс, который используется для описания различных инструментов, опций, механизмов и интерфейсов, поддерживающих реализацию действий -- сбор данных, совместное использование, использование, уведомление в случае изменения политики или нарушения данных. Он используется для характеризации таких свойств, как режим обработки (автоматический или нет), детали реализации деятельности, такие как уведомление по электронной почте или на веб-сайте, доступ к данным через приложение или через конкретный запрос по почте и т.д.

Все упомянутые выше классы связаны друг с другом с помощью свойств, определяющих семантические отношения между ними. На рисунке \ref{fig:figure6} показаны основные концепции и свойства, относящиеся к сценариям использования и сохранения данных. Стрелки соответствуют свойствам, связывающим сущности, их цвет зависит от их типа. На рисунке \ref{fig:figure7} сущности, отмеченные желтыми точками, являются классами, а сущности, отмеченные фиолетовым ромбом, - это объекты, то есть текстовые отрывки, обнаруженные в политике конфиденциальности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Сценарии использования и сохранения данных\label{fig:figure7}}}
    {\includegraphics[width=.8\textwidth]{figure7.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsection{Алгоритм оценки рисков на основе онтологического представления}
Алгоритм оценки рисков конфиденциальности принимает в качестве входных данных онтологию политики конфиденциальности, описывающую 11 сценариев использования.

Основная идея алгоритма заключается в том, что типы персональных данных и их количество определяют основу оценки риска для персональных данных. Другие аспекты, указанные в политике конфиденциальности, такие как цель, правовая основа и варианты подписки/отказа, могут только увеличивать или уменьшать их. Формализующий алгоритм представлен в статье \cite{P2Onto}.

Общая оценка риска на основе анализа онтологии рассчитывается следующим образом \ref{eq:formula1}: 
\begin{equation}
    \label{eq:formula1}
    PrivacyRiskScore = \sum_i{w_i} \cdot UsageScenarioRiskScore_i, \sum_{i}{w_i} = 1,
\end{equation}
\makebox[1.25cm]{где\hfill}$w_i$ -- весовой коэффициент, определяющий влияние оценки риска $i$-го сценария использования данных. 

В текущей версии все $w_i$ равны друг другу, а общая оценка риска рассчитывается следующим образом \ref{eq:formula2}: 
\begin{equation}
    \label{eq:formula2}
    PrivacyRiskScore = \frac{1}{n}\sum^n_{i=1}{w_i} \cdot UsageScenarioRiskScore_i,
\end{equation}
\makebox[1.25cm]{где\hfill}$n$ -- количество анализируемых сценариев использования данных.

Расчет оценки риска конфиденциальности $RiskScoreBase$ основан на критичности типов персональных данных и присвоенных им весах, представленных в таблице \ref{tab:table3}. Идея алгоритма расчета риска конфиденциальности $RiskScoreBase$ заключается в определении типа персональных данных с наивысшей критичностью, присутствии этого типа в тексте политики конфиденциальности, а затем увеличении риска в зависимости от количества различных типов личных данных. Если в тексте политики присутствуют все типы персональных данных, то риски увеличиваются вдвое. Оценка риска увеличивается логарифмически, чтобы избежать быстрого роста оценки риска. 

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|M{.15\x}|M{.3\x}|C{.15\x}|C{.15\x}|}
    
        \caption{Категории персональных данных, их важность и вес\label{tab:table3}} \\\hline
        \multicolumn{1}{|H{.15\x}|}{Классы и подклассы онтологии}
        & \multicolumn{1}{H{.3\x}|}{Категории (класс) } 
        & \multicolumn{1}{H{.15\x}|}{Критичность типа ПД} 
        & \multicolumn{1}{H{.15\x}|}{Влияние категории}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:table3}}\\\hline
        \multicolumn{1}{|H{.15\x}|}{Классы и подклассы онтологии}
        & \multicolumn{1}{H{.3\x}|}{Категории (класс)} 
        & \multicolumn{1}{H{.15\x}|}{Критичность типа ПД} 
        & \multicolumn{1}{H{.15\x}|}{Влияние категории}\\\hline
        \endhead
        \endfoot
        \endlastfoot

        Data
        & Non Personal Data
        & 0
        & 0,0\\
        
        \cline{2-4}

        & Service Data
        & 3
        & 0,9\\
        
        \cline{2-4}

        & Tracking Data
        & 4
        & 1,3\\
        
        \hline

        & User Device Data
        & 2
        & 0,4\\
        
        \cline{2-4}

        & App Data
        & 2
        & 0,4\\
        
        \cline{2-4}

        & Sensitive Data
        & 5
        & 2,2\\
        
        \cline{2-4}

        & User Financial Info
        & 4
        & 1,7\\
        
        \cline{2-4}

        & User Account Data
        & 2
        & 0,4\\
        
        \cline{2-4}

        & Other
        & 3
        & 1,3\\
        
        \cline{2-4}

        & Not defined
        & 3
        & 1,3\\
        
        \hline
        
    \end{longtable}
\end{ltwrap}

Авторы \cite{P2Onto} считают, что эта онтология может служить основой для разработки интерактивных моделей визуализации на основе графов, нацеленных на объяснение рисков конфиденциальности для конечного пользователя в ясной и удобочитаемой форме. 

\subsection{Постановка задачи}
В связи с растущей актуальностью вопросов защиты персональных данных как никогда важными становятся методы формализации политик безопасности и оценки рисков при согласии пользователя на передачу личных данных. Рассмотренные работы в данной области продемонстрировали возможность формализации политик безопасности, а также оценки рисков при согласии с политикой конфиденциальности. Однако, пока не было предложено полностью автоматизированного решения для формализации политик безопасности и оценки рисков. В связи с этим актуальна проблема автоматизации предложенных подходов. 

Таким образом задачей выпускной квалификационной работы является разработка методик и инструментов для сбора и аннотирования данных для поддержки системы формализации политик безопасности, которая в перспективе может быть использована при оценке рисков конфиденциальности.

\newpage
\section{Проектирование инструментария}

\subsection{Применение строгих методов анализа текста для формализации политик безопасности}

Вопреки тенденциям на использование технологий машинного обучения для формализации политик безопасности, были сделаны попытки осуществить формализацию с помощью различных алгоритмов кластеризации.

Основанием для проведения данных экспериментов послужила особенность моделей построенных глубоком обучении -- необходимость наличия размеченной выборки данных для обучения. Сбор данных для этих целей -- трудоемкий процесс, равно как и аннотирование собранных данных.

Поэтому были протестированы различные алгоритмы кластеризации и тематического моделирования. Также была сделана попытка анализа политик безопасности на основе частеречной разметки и контекстно-свободных грамматик.

\subsubsection{Статистические модели текстовых документов}

В рамках экспериментов со строгими методами анализа текстов были протестированы две модели векторизованного представления текста -- Bag-of-Words и TF-IDF. Модель Bag-of-Words представляет документ в виде матрицы, представленной на рисунке \ref{fig:bow}. Здесь слова каждого абзаца подсчитываются и сопоставляются с абзацами, в которых они встретились.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Bag-of-Words матрица\label{fig:bow}}}
    {\includegraphics[width=.7\textwidth]{bow.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Модель TF-IDF представляет документ в виде матрицы, представленной на рисунке \ref{fig:tfidf}. Формула (\ref{eq:tfidf}) показывает, как можно получить метрику TF-IDF.
\begin{equation}
    \label{eq:tfidf}
    tfidf(t, d, D) = \frac{n_t}{\displaystyle\sum_k n_k} \times 
    log \frac{ \big|{D}\big| }
    { \big|\left\{ d_i \in D : t \in d_i \right\}\big| }\ ,
\end{equation}
\makebox[1.25cm]{где\hfill}$t$ -- термин или слово;\\
\makebox[1.25cm]{}$d$ -- конкретный абзац;\\
\makebox[1.25cm]{}$D$ -- набор абзацев. 

Итак, модель TF-IDF придает больший вес словам которые использованы меньше раз. Это может быть полезно, когда тексты схожи с точки зрения используемых слов, как в случае с политиками безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Матрица TF-IDF\label{fig:tfidf}}}
    {\includegraphics[width=.7\textwidth]{tfidf.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Подход основанный на латентно-семантическом анализе текста}

Современные методы кластеризации текстов позволяют определять тематику текстов с высокой точностью. Однако, большинство из этих методов принимают тексты с самыми разными темами как вход для алгоритмов. Тексты со схожими тематиками можно проанализировать с помощью ла\-тен\-тно-семантического анализа дважды: группировать тексты по темам один раз, и предоставить еще более детальное разделение их по подтемам во второй раз. Такой подход можно использовать для более точной классификации абзацев с точки зрения их характеристик и аспектов использования персональных данных. Следует отметить, что латентно-семантический поиск сильно зависит от глобального текстового контекста с потерями информации о локальных контекстных отношениях между словами. Были выделены девять тем конфиденциальности, которые следует сопоставить с абзацами согласия пользователя сайта -- <<сбор личных данных>>, <<сбор данных третьими лицами>>, <<управление личными данными>>, <<механизмы защиты персональных данных>> и другие. Очевидно, что аспекты обращения с данными состоят из нескольких слов, и в некоторых случаях перекрываются. На основании этих фактов была выдвинута гипотеза о том, что латентно-семантический поиск способен обнаружить даже незначительную разницу в тексте абзацев при пропуске частых слов. Перед применением латентно-семантического анализа требуется предварительная обработка входных данных. Обычно эта процедура включает в себя очистку данных, удаление гиперссылок, пунктуации и т.д. Также текст политик конфиденциальности был разбит на массив абзацев. Каждый абзац был преобразован в массив слов, которые он содержит. Следующим шагом было удаление наиболее частых, но не столь значимых слов, так называемых стоп-слов. Наконец была применена операция стемминга, чтобы рассматривать только основную часть всех слов полученных от единого корня.

Пусть A -- это матрица абзацев и слов, тогда формула (\ref{eq:lsa}) будет следующей:
\begin{equation}
    \label{eq:lsa}
    A = U \times S \times V^T,
\end{equation}
\makebox[1.25cm]{где\hfill}$A$ -- матрица слов и параграфов;\\
\makebox[1.25cm]{\hfill}$U$ -- ортонормированная матрица $U$;\\
\makebox[1.25cm]{\hfill}$V$ -- ортонормированная матрица $V$;\\
\makebox[1.25cm]{\hfill}$S$ -- диагональная матрица $S$, значения которой сингулярны для $A$.

После того, как матрица была разделена на три компоненты, матрица $U$ содержит $n$-мерные векторы, которые можно интерпретировать как координаты в $n$-мерном пространстве \cite{LSA}. Документы могут быть распределены по кластерам по значениям этих координат. Проведенные эксперименты с латентно-семантическим анализом выполнялись с использованием набора данных с открытым исходным кодом, который включает 115 политик безопасности, которые были размечены вручную, и все абзацы присвоены одному или нескольким сценариям использования персональных данных \cite{MDPI18}. Результаты экспериментов для модели Bag-of-Words представлены в таблице \ref{tab:clusters1}, в ней показаны полученные кластеры и соответствующие значения координат.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|C{.05\x}|M{.2\x}|M{.2\x}|M{.2\x}|M{.2\x}|}
        \caption{Кластеры политик безопасности для модели Bag-of-Words\label{tab:clusters1}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.2\x}|}{Координата 1} 
        & \multicolumn{1}{H{.2\x}|}{Координата 2} 
        & \multicolumn{1}{H{.2\x}|}{Координата 3} 
        & \multicolumn{1}{H{.2\x}|}{Координата 4}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:clusters1}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.2\x}|}{Координата 1} 
        & \multicolumn{1}{H{.2\x}|}{Координата 2} 
        & \multicolumn{1}{H{.2\x}|}{Координата 3} 
        & \multicolumn{1}{H{.2\x}|}{Координата 4}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        0 & 0.634 inform  & 0.280 may        & 0.276 use     & 0.232 servic   \\\hline
        1 & 0.202 cooki   & 0.466 inform    & 0.336 site    & 0.257 use      \\\hline
        2 & 0.524 privaci & 0.433 polici    & 0.388 cooki   & 0.219 site     \\\hline
        3 & -0.589 servic & 0.344 site      & 0.244 parti   & -0.240 third   \\\hline
        4 & -0.504 parti  & 0.486 third    & -0.449 servic & 0.235 advertis \\\hline
        5 & -0.594 site   & 0.278 cooki     & 0.272 websit  & 0.264 privaci  \\\hline
        6 & -0.326 may    & 0.311 site      & 0.307 servic  & -0.293 email   \\\hline
        7 & -0.437 may    & -0.369 advertis & 0.345 person  & 0.319 cooki    \\\hline
        8 & 0.501 may     & -0.315 email    & -0.281 use    & -0.264 address \\\hline
        9 & -0.488 user   & -0.384 use      & 0.310 provid  & -0.301 websit  \\\hline
    \end{longtable}
\end{ltwrap}

Как видно, результаты противоречивы, поэтому трудно понять, какая из тем каким смыслом обладает. Затем рассчитывалась метрика принадлежности к теме с помощью библиотеки Gensim \cite{Gensim} и результаты снова не были обнадеживающими. Результаты расчета метрики принадлежности кластеру представлены в таблице \ref{tab:affiliation_bow1}.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|M{.13\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|}
        \caption{Принадлежность кластерам\label{tab:affiliation_bow1}}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:clusters1}}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        Topic       & 0     & 1     & 2    & 3     & 4     \\\hline
        Affiliation & 2.27  & -0.8  & 0.15 & -0.22 & -1.2  \\\hline
        Topic       & 5     & 6     & 7    & 8     & 9     \\\hline
        Affiliation & -0.17 & -0.15 & -0.2 & 0.22  & -0.07 \\\hline
    \end{longtable}
\end{ltwrap}

Другие результаты с параграфами, относящимися к другому аспекту обращения с данными, были почти такими же. Результаты
представлены в таблице \ref{tab:affiliation_bow2}.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|M{.13\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|}
        \caption{Принадлежность кластерам\label{tab:affiliation_bow2}}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:clusters1}}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        Topic       & 0    & 1     & 2    & 3    & 4    \\\hline
        Affiliation & 2.59 & -0.76 & 0.64 & 0.74 & 0.13 \\\hline
        Topic       & 5    & 6     & 7    & 8    & 9    \\\hline
        Affiliation & 0.14 & -0.12 & 0.23 & 0.12 & 0.41 \\\hline
    \end{longtable}
\end{ltwrap}

Все протестированные абзацы были сопоставлены с кластером 0, что не может быть верным так как абзацы относились к заведомо разным аспектам обращения с персональными данными. 

Результаты экспериментов для модели TF-IDF представлены далее, в таблице \ref{tab:clusters2}. Также показывались десять кластеров и координаты в семантическом пространстве. И, как в первом случае с <<мешком слов>>, по значениям координат невозможно судить о теме кластера.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|C{.05\x}|M{.2\x}|M{.2\x}|M{.2\x}|M{.2\x}|}
        \caption{Кластеры политик безопасности для модели TF-IDF\label{tab:clusters2}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.2\x}|}{Координата 1} 
        & \multicolumn{1}{H{.2\x}|}{Координата 2} 
        & \multicolumn{1}{H{.2\x}|}{Координата 3} 
        & \multicolumn{1}{H{.2\x}|}{Координата 4}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:clusters2}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.2\x}|}{Координата 1} 
        & \multicolumn{1}{H{.2\x}|}{Координата 2} 
        & \multicolumn{1}{H{.2\x}|}{Координата 3} 
        & \multicolumn{1}{H{.2\x}|}{Координата 4}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        0 & 0.202 cooki     & 0.2 may        & 0.198 inform   & 0.198 site     \\\hline
        1 & 0.573 cooki     & 0.262 browser  & 0.195 advertis & 0.182 web      \\\hline
        2 & -0.406 media    & 0.291 cooki    & 0.282 health   & 0.279 advertis \\\hline
        3 & -0.453 health   & 0.258 email    & -0.204 kaleida & 0.191 address  \\\hline
        4 & 0.423 health    & 0.215 media    & 0.205 kaleida  & -0.199 secur   \\\hline
        5 & -0.299 advertis & 0.262 health   & -0.252 media   & -0.213 privaci \\\hline
        6 & -0.325 media    & 0.263 polici   & 0.249 privaci  & 0.197 chang    \\\hline
        7 & 0.280 cooki     & -0.216 device  & -0.183 health  & -0.166 social  \\\hline
        8 & -0.223 advertis & -0.206 teenag  & -0.206 inelig  & 0.176 child    \\\hline
        9 & -0.263  child   & -0.26 wireless & 0.245 message  & 0.239 parent   \\\hline
    \end{longtable}
\end{ltwrap}

Результаты кластеризации снова противоречивы, поэтому трудно сказать, какая конкретная тема какой аспект политики конфиденциальности описывает. В разных темах встречаются одни и те же слова с изменением веса. Для искомых аспектов политики конфиденциальности нет тем, которые могли бы их точно описать. Затем с помощью библиотеки Gensim был рассчитан показатель принадлежности к теме, и результаты снова не были обнадеживающими. Результаты расчета аффилиации абзаца одной из политик конфиденциальности к полученным кластерам представлены в таблице \ref{tab:affiliation_tfidf1}.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|M{.13\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|}
        \caption{Принадлежность кластерам\label{tab:affiliation_tfidf1}}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:affiliation_tfidf1}}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        Topic       & 0    & 1     & 2     & 3     & 4     \\\hline
        Affiliation & 2.18 & -0.97 & -0.69 & -0.27 & 0.65  \\\hline
        Topic       & 5    & 6     & 7     & 8     & 9     \\\hline
        Affiliation & 0.98 & -1.17 & 0.8   & 0.27  & 0.01  \\\hline
    \end{longtable}
\end{ltwrap}

Результат для другого абзаца, относящегося к другой политике конфиденциальности, был почти такой же. Результаты представлены в таблице \ref{tab:affiliation_tfidf2}.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|M{.13\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|C{.1\x}|}
        \caption{Принадлежность кластерам\label{tab:affiliation_tfidf2}}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:affiliation_tfidf2}}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        Topic       & 0    & 1    & 2     & 3     & 4     \\\hline
        Affiliation & 1.82 & 0.25 & 0.49  & 0.29  & -0.04 \\\hline
        Topic       & 5    & 6    & 7     & 8     & 9     \\\hline
        Affiliation & 0.74 & 0.52 & -0.04 & -0.58 & -1.33 \\\hline
    \end{longtable}
\end{ltwrap}

Как можно заметить, результаты для модели TF-IDF аналогичны результатам модели Bag-of-Words, за исключением нескольких незначительных изменений. Все абзацы снова были сопоставлены с кластером 0, что неверно, потому что они на самом деле описывают разные сценарии использования персональных данных. Эти эксперименты позволили сделать вывод, что использование латентно-семантического анализа не дает ценной информации о содержании онлайн-согласия пользователя. Проблема может быть связана с тем, что сценарии использования персональных данных очень похожи между собой, и для того, чтобы различать разные сценарии необходимо учитывать локальный контекст.

В результате апробации алгоритма латентно-семантического анализа было выяснено, что для кластеризации экстремально схожих между собой текстов он подходит не лучшим образом.

\subsubsection{Подход основанный на латентном размещении Дирихле}

Для тестирования латентного размещения Дирихле был как и ранне выбран датасет OPP-115 с открытым исходным кодом \cite{MDPI18}. В большинстве случаев аспекты относятся к абзацам текста, а некоторые абзацы относятся к нескольким категориям одновременно. На рисунке \ref{fig:opp1} показано распределение абзацев по категориям. Хорошо видно, что есть две основные категории – <<Third-party Sharing/Collection>> и <<First-party Collection and Use>>, которые преобладают над остальными.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение по сценариям использования данных\label{fig:opp1}}}
    {\includegraphics[width=.8\textwidth]{last1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Чтобы применить LDA к анализу политики конфиденциальности, тексты политик конфиденциальности были разбиты на набор абзацев. Каждый абзац был преобразован в массив слов, а затем удалены наиболее частые, но не значащие слова, так называемые стоп-слова. Также была выполнена лемматизация, чтобы обобщить некоторые слова, для получения более точных результатов.

В ходе экспериментов как и раннее были протестированы две модели векторизации текста – Bag-of-Words и TF-IDF, и оказалось, что метрика TF-IDF предоставляет более подробную информацию о сценариях использования данных, поскольку эта модель векторизации дает более высокие веса словам, которые реже используются.

Оптимальное количество кластеров, то есть семантических моделей, было определено как 15, поскольку такое значение соответствует максимальному значению когерентности, рассчитанному с помощью библиотеки Gensim \cite{MDPI13}. Важно отметить, что это число отличается от числа категорий, обозначенных создателями набора данных OPP-115.

Результаты экспериментов для модели TF-IDF показаны в таблице \ref{tab:advanced_modeling}. В таблице \ref{tab:advanced_modeling} приведен список координат, которые формируют семантические модели тем. Координаты используются для составления гипотезы об использовании личных данных и сценариях их применения.

Хорошо видно, что большинство извлеченных моделей посвящено сценариям <<First-Party Collection and Use>> и <<Third-Party Sharing/Collection>>. Это полностью соответствует распределению категорий в наборе данных. Абзацы различаются характеристиками семантических моделей. Например, тематическая модель 9 раскрывает варианты согласия/отказа при обмене личными данными в рекламных целях, тематическая модель 6 посвящена использованию файлов cookie первыми и третьими сторонами, некоторые тематические модели предоставляют информацию о типах собираемых личных данных: информация об учетной записи пользователя (тематическая модель 7), финансовые данные (тематическая модель 2), данные отслеживания местоположения и аналитики (тематическая модель 11). Некоторые темы, такие как тематические модели 4 и 10, раскрывают довольно специфические аспекты использования личных данных, такие как безопасность данных, включая случай, когда данные передаются третьим лицам, и уведомление в случае изменения политики. Некоторые тематические модели являются довольно общими, например, модели характеризуют очень общие проблемы, связанные со сбором данных первой стороной и сторонним совместным использованием 0,1 и 3.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|C{.05\x}|M{.475\x}|M{.475\x}|}
        \caption{Тематическое моделирование\label{tab:advanced_modeling}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.475\x}|}{Координаты семантического пространства} 
        & \multicolumn{1}{H{.475\x}|}{Возможные сценарии использования}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:advanced_modeling}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.475\x}|}{Координаты семантического пространства} 
        & \multicolumn{1}{H{.475\x}|}{Возможные сценарии использования}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        0 & service, friend, story, child, cookie, use, product, email, compromised, card & First-party collection \& usage (usage of cookies, e-mail), Special audience (children) \\\hline
        1 & schedule, channel, analytic, happy, website, gather, address, mingle, moreover, identifiable & First-party collection (identifiable user data) \\\hline
        2 & collect, credit, card, us, address, pursuant, email, service, personal, may & First-party collection: payment credentials \\\hline
        3 & state, united, asset, website, policy, personal, privacy, party, third, sm & Third-party sharing \\\hline
        4 & security, personal, rating, site, u, disclosure, service, policy, physical, third & Data security (including third-party sharing)  \\\hline
        5 & party, third, child, service, cookie, personal, personally, site, company, identifiable & Third-party sharing (usage of cookies) \\\hline
        6 & service, website, personal, site, cookie, party, third, data, use, us & First-party collection \& Third-party sharing (for: services provision, usage of website data and cookies) \\\hline
        7 & personal, service, account, information, site, device, u, may, provide, use & First-party collection: user account information \\\hline
        8 & device, resume, message, policy, privacy, social, service, site, website, networking & Other \\\hline
        9 & opt, collect, site, third, advertising, personal, party, service, u, privacy & First-party collection \& Opt-in, opt-out for advertising \\\hline
        10 & military, change, policy, time, site, web, page, privacy, cookie, post & Privacy policy change, including notification mechanism \\\hline
        11 & navigating, service, google, non, adsense, nielsen, account, collect, device, privacy & First-party collection: device and location information \\\hline
        12 & station, feedback, service, consented, java, script, merchant, cookie, child, st & Other \\\hline
        13 & cookie, service, third, party, site, website, california, flash, use, technology & Third-party sharing \& Special audience: California residents \\\hline
        14 & child, forum, trade, age, pii, conversation, chat, branded, personal & Special audience: children \\\hline
    \end{longtable}
\end{ltwrap}

Однако необходимо учитывать, что политики конфиденциальности в большинстве случаев являются очень общими и неструктурированными, они не содержат четкой спецификации действий по обработке данных. Для некоторых тематических моделей было сложно определить аспекты сценариев использования, они были объединены в группу <<Other>>.

Также стоит отметить, что не было выявлено моделей, посвященных хранению данных и аспектам доступа, редактирования и удаления данных. Это могло произойти из-за того, что количество абзацев, содержащих эту информацию, невелико, и они семантически довольно близки к сценарию <<First-Party Collection and Use>>. Напротив, были найдены темы посвященные аспектам <<International and Special Audience>>, <<Data Security>> и <<Privacy Policy Change>>, хотя количество их вхождений в наборе данных сопоставимо с <<Data Retention>> и <<User Access, Edit and Deletion>>.

Используя извлеченные тематические модели, было проанализировано содержание политик конфиденциальности и вручную оценена точность кластеризации абзацев для набора выбранных политик. Например, для политики конфиденциальности Xiaomi \cite{MDPI14} была получена точность 69\%. На рисунке \ref{fig:opp2} показано распределение семантических тематических моделей абзацев в тексте политики конфиденциальности Xiaomi. Отчетливо видно, что большая часть документа посвящена описанию различных аспектов <<First-Party Collection and Use>> – указанию, какие типы данных собираются, есть ли какие-либо варианты выбора/отказа. Полученные результаты также сравнивались с результатами \cite{MDPI7} с помощью онлайн-инструмента Pribot \cite{Polisis}. Сравнительный анализ показал, что LDA выявило все основные аспекты использования персональных данных, за исключением одной целевой детской аудитории. Когда была перепроверена политика Xiaomi, выяснилось, что данному аспекту было посвящено лишь одно предложение.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение по сценариям использования данных, полученное с помощью LDA\label{fig:opp2}}}
    {\includegraphics[width=.8\textwidth]{last2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Подход основанный на применении контекстно-свободных грамматик и синонимическом поиске}

Другой предложенный подход -- подход, основанный на анализе с помощью контекстно-свободных грамматик и синонимического поиска. Синонимический поиск в данном случае -- это подмена ключевых слов и их синонимов метками, например <<\_\_FP\_A\_\_>> означает, что это слово и его синонимы считаются акторами (первым лицом). Этот метод можно применить ко многим другим концепциям. Например, сообщения электронной почты, аватары, местоположение также могут быть объектами и синонимами абстрактной метки <<\_\_CN\_\_>>, которая означает существительное сбора или объект сбора. Так все ключевые слова могут быть преобразованы в их смыслы в контексте предметной области. Маркировка выполняется просто, все слова, совпадающие с пулами, заменяются метками этих пулов.

Предварительная обработка данных в данном случае состоит из токенизации и лемматизации для более гибкой замены слов на метки их пулов.

При анализе пользовательского согласия сайта недостаточно найти ключевые слова, относящиеся к разным типам персональных данных, например цель и правовую основу распознать гораздо сложнее. Следующий шаг -- установить отношения между словами в предложениях, чтобы можно было определенно сказать, что ярлыки пулов синонимов связаны друг с другом и формируют логическая цепочку. Один из возможных способов определения отношений слов в тексте на естественном языке -- это синтаксический анализ предложения, основанный на частеречной разметке \cite{POS}. Имея размеченное по частям речи предложение, парсер грамматики NLTK \cite{NLTK} строит деревья предложений по правилам грамматики. Одно из таких деревьев в обозначениях NLTK можно увидеть на рисунке \ref{fig:nltk_tree} \cite{NLTK}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример грамматического разбора\label{fig:nltk_tree}}}
    {\includegraphics[width=.7\textwidth]{tree.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Здесь <<S>> -- основа предложения, <<NP>> -- именная фраза, <<VP>> -- глагольная фраза, <<Adj>> -- прилагательное, <<НОМ>> -- именное словосочетание, <<ПП>> -- предлог фраза, <<Det>> -- артикль, <<V>> -- глагол, <<N>> -- существительное, <<P>> -- предлог.

В предлагаемом подходе немного другая грамматическая запись. Созданная грамматика представлена в (\ref{eq:grammar1}). 
\begin{equation}
    \label{eq:grammar1}
    \left\{ 
        \begin{array}{l}
            D \rightarrow S\ |\ S\ D\ |\ S\ \ U\ D\ \\
            S \rightarrow NPG\ \ \ VBG \\
            VPG \rightarrow VP\ |\ VP\ \ VPG\ |\ VP\ \ U\ \ VPG \\
            NPG \rightarrow NP\ |\ NP\ \ NPG\ |\ NP\ \ U\ \ NPG \\
            AJPG \rightarrow AJ\ |\ AJ\ \ APG\ |\ AJ\ \ U\ \ APG \\
            AVPG \rightarrow AV\ |\ AV\ \ APG\ |\ AV\ \ U\ \ APG \\
            VP \rightarrow V APG\ |\ V\ \ PPG\ |\ V\ \ PP\ \ APG \\
            NP \rightarrow NOM\ |\ DET\ \ NOM \\
            NOM \rightarrow N\ |\ AJPG\ \ N \\
            PP \rightarrow NPG\ |\ P\ \ NPG
        \end{array}
    \right.\ ,
\end{equation}
\makebox[1.25cm]{где\hfill}$D$ -- документ,\\
\makebox[1.25cm]{}$SB$ -- синтаксическая основа предложения с его зависимостями,\\
\makebox[1.25cm]{}$U$ -- союз,\\
\makebox[1.25cm]{}$NPG$ -- группа именных фраз,\\
\makebox[1.25cm]{}$VPG$ -- группа глагольных фраз,\\
\makebox[1.25cm]{}$AJPG$ -- группа однородных прилагательных,\\
\makebox[1.25cm]{}$AVPG$ -- группа однородных наречий,\\
\makebox[1.25cm]{}$PPG$ -- группа однородных дополнений,\\
\makebox[1.25cm]{}$VP$ -- глагольная группа,\\
\makebox[1.25cm]{}$NP$ -- именная группа,\\
\makebox[1.25cm]{}$NOM$ -- номинальная группа,\\
\makebox[1.25cm]{}$P$ -- предлог,\\
\makebox[1.25cm]{}$AJ$ -- прилагательное,\\
\makebox[1.25cm]{}$AV$ -- наречие,\\
\makebox[1.25cm]{}$PP$ -- существительное с предлогом,\\
\makebox[1.25cm]{}$N$ -- существительное,\\
\makebox[1.25cm]{}$V$ -- глагол,\\
\makebox[1.25cm]{}$DET$ -- определяющее слово.

Грамматика из формулы (\ref{eq:grammar1}) позволяет рекурсивно выделять основу предложения и последовательности глагола, существительного, прилагательного, наречия и т.д. Это все еще не идеальное решение, но способное обрабатывать довольно сложные предложения в политиках безопасности. Этот подход требует использования пулов синонимов, которые соответствуют различным ключевым словам. Поэтому в грамматику включены метки пулов синонимов, привязанных к части речи. Метки пулов вручную назначены частям речи для связи их с нотацией частей речи NLTK, это показано в формуле (\ref{eq:grammar2}).
\begin{equation}
    \label{eq:grammar2}
    \left\{ 
        \begin{array}{l}
            U \rightarrow NLTK\_CC \\
            DET \rightarrow NLTK\_DT \\
            AJ \rightarrow NLTK\_JJ \\
            AV \rightarrow NLTK\_RB \\
            N \rightarrow \_\_CN\_\_\ |\ \_\_FP\_A\_\_\ |\ \_\_TP\_A\_\_\ |\ NLTK\_N \\
            V \rightarrow \_\_CV\_\_\ |\ NLTK\_V
        \end{array},
    \right. 
\end{equation}
\makebox[1.25cm]{где\hfill}$NLTK\_CC$ -- соединение NLTK,\\
\makebox[1.25cm]{}$NLTK\_N$ -- все формы существительных NLTK,\\
\makebox[1.25cm]{}$NLTK\_В$ -- все формы глаголов NLTK,\\
\makebox[1.25cm]{}$NLTK\_DET$ -- определители NLTK,\\
\makebox[1.25cm]{}$NLTK\_RB$ -- все формы наречий NLTK,\\
\makebox[1.25cm]{}$\_\_FP\_A\_\_$ -- метка актора-обладателя персональных данных,\\
\makebox[1.25cm]{}$\_\_TP\_A\_\_$ -- третья сторона,\\
\makebox[1.25cm]{}$\_\_CV\_\_$ -- глагол сбора,\\
\makebox[1.25cm]{}$\_\_CN\_\_$ -- существительное сбора.

Теги, начинающиеся с подчеркивания, являются метками пулов синонимов. Синтаксический анализ выполняет библиотека NLTK. На основе предложенной грамматики, описанной (\ref{eq:grammar1}) и (\ref{eq:grammar2}) и меток пулов было построено дерево тестового предложения, результат на рисунке \ref{fig:tree}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Дерево грамматического разбора\label{fig:tree}}}
    {\includegraphics[width=.7\textwidth]{labeled_tree.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Когда было построено дерево предложений, последовательность меток ключевых слов может быть распознана. В этом случае представленная на рисунке \ref{fig:tree}, последовательность <<\_\_FP\_A\_\_>>, <<\_\_CV\_\_>>, <<\_\_CN\_\_>> хорошо видна. Такие простейшие последовательности, раскрывают значения частей предложения и могут быть объединены в список, после этого весь смысл документов будет описан этим списком. Сочетание маркировки ключевых слов и синтаксического анализа дает значения ключевых слов с отношениями между этими словами, определенными в виде древовидных структур. Дерево структура данных более гибкая, чем строка предложения, деревья и особенно поддеревья показывают важные отношения между словами. Запросы к таким структурам могут дать необходимую информацию для построения логических последовательностей действующих лиц, их действий, субъектов этих действий и, наконец, обстоятельств. Предлагаемый подход определенно имеет такие недостатки, как низкая производительность, вручную определенные пулы синонимов и т.д.

\subsubsection{Выводы по строгим методам текстового анализа}

Эксперименты показали, что оба рассмотренных метода имеют как преимущества, так и определенные недостатки. Хотя предложенные подходы, оказались противоречивыми, окончательные результаты заслуживают внимания. Подход с латентно-семантическим поиском оказался не слишком эффективным. Однако, подход основанный на грамматическом анализе предложений и синонимическом поиске дал определенные результаты. Хоть он и не является производительным, с его помощью возможно производить выделение логических цепочек из предложений для получения более формального описания политик безопасности нежели их текстовые варианты. Алгоритм LDA показал наилучшие результаты, однако этих результатов все же не достаточно для выявления таких тонких сущностей как аттрибуты классов, представленных в онтологии из работы \cite{P2Onto}.

Исходя из проведенных исследований стало понятно, что более предпочтительным вариантом решения задачи будет подход с применением моделей глубокого обучения. Реализация подобного проекта -- комплексная задача, ее можно разделить на несколько этапов. Сначала необходимо собрать датасет, потом разметить его для обучения модели, далее обучить модель и получить результаты. Однако, сбор датасета тоже является непростой задачей. Необходимость сбора нового датасета обусловлена еще и принятием GDPR в качестве основного документа, регулирующего обработку, хранение и использование персональных данных, в то время как существующие датасеты состоят из устаревших документов. Для того, чтобы осуществить сбор датасета необходим инструмент для поиска и скачивания веб-страниц из сети Интернет. Затем необходимо произвести очистку данных, удалить все теги со страниц, чтобы можно было передать текст аннотаторам. Все этапы сбора датасета полагаются на базу данных. Она лишена сложного объектно-реляционного моделирования, так как в ней по сути необходимо только хранить промежуточные результаты обработки текстовых материалов.

\subsection{Техническое задание <<Инструментарий для сбора датасета>>}

\subsubsection{Скрейпер веб-страниц}
Скачивание веб-страниц будет производиться инструментом, написанным на языке Python, с помощью библиотек можно скачивать страницы, анализировать данные содержащиеся в них, переходить по гиперссылкам и много другое. Такой инструмент позволит просматривать и сохранять содержимое страниц в автоматическом режиме без вмешательства пользователя. Таким образом, в автоматическом режиме можно сохранить и проанализировать огромное количество текстовой информации.

\subsubsection{Очистка скачанных страниц политик}
Для очистки страниц от кода разметки планируется использовать библиотеку html-sanitizer. Очистка кода необходима для того, чтобы аннотаторы могли максимально сфокусироваться на анализе текста, таким образом, получая чистый текст, они не будут отвлекаться на не имеющие значения в контексте задачи фрагменты.

\subsubsection{Инструмент разметки датасета}
Инструмент разметки датасета планируется реализовать с помощью веб-технологий. Серверная часть будет полагаться на приложение, написанное на языке PHP, которое будет регулировать порядок выдачи текста на аннотирование. Процесс разметки высокодинамичен, поэтому невозможно избежать написания качественной клиентской части приложения на языке javascript. Это позволит сделать работу аннотаторов максимально производительной, в одну сессию (страница не будет перезагружаться).

\subsubsection{Фреймворки глубокого обучения}
Аннотированный датасет должен быть легко адаптируемым для создания и тренировки модели анализа текста с использованием современных фреймворков машинного обучения, таких как Keras, PyTorch и другие. Они позволят быстро создавать классификаторы самых разных конфигураций и типов.

После того как классификатор будет сконфигурирован, останется лишь обучить его на датасете, полученном ранее.

Обученный классификатор будет способен определять различные характеристики политики безопасности и аспекты обращения с данными, что позволит в автоматическом режиме формализовать политики конфиденциальности, формировать отчеты о безопасности предоставляемого соглашения на основе алгоритмов, предложенных в \cite{P2Onto}.

\subsection{Методика сбора}
Планируя решение появившейся задачи, важно уделить внимание источникам данных для сбора, потому что без них невозможно будет продолжать работу. Это важно еще и потому, что необходимо будет адоптировать инструмент сбора данных под конкретные веб-ресурсы, так как на каждом из них реализована собственная html-разметка.

Исходя из ориентированности датасета на умные устройства, логичным выглядит обращение к крупным торговым площадкам, так как они занимаются дистрибуцией подобных устройств. На сайтах торговых площадок можно осуществлять поиск продукции и получать данные о ней, в том числе и производителя продукции. Типовая разметка веб-страниц располагает для получения такой информации, так как существует лишь несколько вариантов наполнения страницы продукции.

Торговые площадки не предоставляют ссылки на официальные сайты производителей. Поэтому необходимо организовать поиск официальных сайтов производителей. Поисковые движки предоставляют API для поиска, однако некоторые из них являются платными, другие выдают совершенно неприемлемые результаты. С другой стороны использование поисковых движков, предназначенных для реальных пользователей, дает наилучшие результаты из возможных, скорее всего это связано с клиентоориентированностью, то есть получая запрос близкий к наименованию бренда с большей вероятностью будет выдана официальная страница производителя в сети Интернет.

Далее важной задачей является определение, какая из ссылок в результате запроса наиболее четко соответствует искомому производителю. Получение официальных веб-сайтов производителей задача на первый взгляд сложная, однако результаты ручной проверки показали, что лучшим вариантом является поисковый запрос с названием производителя и типом устройства. В таком случае веб-сайт производителя оказывается на первой странице результата поискового запроса, а если не оказывается, значит у этой компании его с очень большой вероятностью нет. 

Получив ссылки предполагаемых официальных сайтов, появляется возможность получить доступ к страницам, на которые они ведут. Поиск политики безопасности на уже обнаруженном сайте производителя является тривиальной задачей. Сейчас на абсолютном большинстве сайтов в футере имеется ссылка, названная как <<Privacy>> или <<Privacy Policy>>. Футер доступен на любой странице сайта и является частью глобальной навигационной системы сайта, в него вынесена информация, которая пригождается не так часто как, например, информация из верхних панелей и меню, однако тем не менее эта информация важна, и помимо ссылок на политику безопасности зачастую содержит контактные данные и прочую организационную информацию.

Таким образом можно получить ссылки на политики безопасности производителей умной продукции. Далее необходимо произвести обработку скачанных политик безопасности.

\subsection{Методика очистки}

Очистка политик безопасности является комплексной задачей. Получив политику безопасности, необходимо удалить все теги, которые несут в себе динамику, то есть все элементы управления. Такие элементы как всплывающие, модальные, диалоговые окна тоже не могут содержать текст политики безопасности. Изображения, помещенные на странице, так же не относятся к политике безопасности. Таким образом получается, что большое количество тегов необходимо в агрессивной манере удалять еще до начала анализа страницы, так как они точно не содержат полезной информации.

Далее необходимо применить обработку, которая включала бы в себя преобразование разметки: недопустимые теги должны быть развернуты, определенные комбинации вложенных тегов должны быть заменены на более тривиальные. Также необходимо очистить теги от атрибутов, так как в них не содержится полезной информации или чего-либо способного положительно сказаться на структуре очищенного документа. Затем по всему дереву DOM осуществляется рекурсивный обход с целью слияния тегов, где это возможно, или оборачивания сырых текстов. В ходе данного этапа также производится нормализация пунктуации и настройка отступов в текстах, чтобы привести их к читабельному виду. 

После указанных двух этапов очистки, следует заключительный, на котором из тегов извлекается текст, то есть параграфы, представленные в виде одной длинной строки. Это делается потому, что расставленные определенным образом переводы на новую строку могут по тем или иным причинам не подходить, и это будет более гибким решением, потому что где требуется можно применить автоматический перенос на новую строку.

\subsection{Методика разметки}
Ключевой в вопросе разметки является идея онтологического представления предметной области. Разметка текста -- процесс интуитивный -- <<что вижу, то получаю>>. Из этого обстоятельства вытекает определенная проблематика:
\begin{itemize}
    \item онтологическое представление сложно организовать на месте, прямо в тексте;
    \item разметка текста ограничена с точки зрения информативности, сложной является задача отображения текста таким образом, чтобы били видны и понятны все метки, присвоенные фрагментам текста;
    \item разметка текста не должна нарушать его целостное восприятие, в противном случае чтение будет затруднено;
    \item пересечение маркированных фрагментов текста.
\end{itemize}

Онтологическое представление это прежде всего графовое представление, при наложении нескольких базовых слоев разметки с сущностью, которая может относиться к обоим этим слоям, может возникнуть неоднозначность. Для ее разрешения необходимы дополнительные усложнения интерфейсной части. Такое усложнение может плохо сказаться на восприятии информации пользователем. Кроме того, это неоправданное усложнение и программного кода. Решение этой проблемы можно найти на уровне проектирования -- совершенно не обязательно представлять разметку как онтологию. При этом может показаться, что происходит отказ от онтологического представления предметной области. Представив онтологию в виде иерархии, разъединив ее на определенных вершинах можно получить валидную иерархию, которая будет гораздо органичнее укладываться в концепцию разметки текста. По завершении аннотирования можно будет обратным образом объединить иерархии, полученные в ходе аннотирования, в онтологии, тем самым выполнив требование по онтологическому представлению предметной области.

Многослойное аннотирование сложно представить каким-либо отличным образом от представленного на рисунке \ref{fig:pics_labeling}. 

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример разметки текста\label{fig:pics_labeling}}}
    {\includegraphics[width=.8\textwidth]{pics_labeling.pdf}}
    \vspace{-\baselineskip}
\end{figure}

На данном рисунке показан макет фрагмента аннотации. При таком подходе информация о разметке не отделена от текста, представляет с ним одно целое. Использование всплывающих окон и подсказок нецелесообразно, так как они своим появлением будут перекрывать текст, мешая его восприятию. Вместо этого предлагается более статичный вариант отображения и наложения новых слоев, представленный в разделе \ref{sec:ui}.

Язык гипертекстовой разметки обладает рядом особенностей, которые препятствуют простому решению проблемы пересечения разметки. Ключевым моментом в этом является древовидное представление документа -- DOM. Любое пересечение в рамках данной структуры является невалидным и соответственно не будет работоспособным. Поэтому предлагается в местах начала и окончания аннотированных фрагментов применять разбиение на 3 фрагмента. Первый -- текст, который шел до выделения, текст самого выделения, текст идущий после выделения. При этом элемент документа будет иметь глубину вложенности не более 1 уровня, что фактически означает разворот иерархии в ширину на уровне языка гипертекстовой разметки. Однако, построение иерархической структуры разметки невозможно при использовании всего лишь 1 уровня вложенности. Решение представлено на рисунке \ref{fig:pics_layers_architecture}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Схема решения с учетом пересечения разметки\label{fig:pics_layers_architecture}}}
    {\includegraphics[width=.8\textwidth]{pics_layers_architecture.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Расширения глубины иерархии разметки можно добиться с помощью других средств. Так как гипертекстовая разметка в данном случае не может быть адаптирована, то хранение иерархии разметки может производиться во вспомогательных структурах данных -- стеках. Ассоциировав с каждым элементов разметки такой стек, можно манипулировать уровнями разметки текста без повреждения гипертекстовой разметки. 

\subsection{Потенциальные проблемы}
Еще до решения задачи были выделены потенциальные проблемы, способные замедлить процесс разработки и сбора датасета. Потенциально возможные проблемы при реализации приложений подобного типа следующие:
\begin{enumerate}
    \item блокировка из-за подозрительных заголовков браузера,
    \item блокировка из-за слишком частого обращения с запросами,
    \item как следствие 2-х предыдущих пунктов требование подтвердить, что это не попытка автоматического доступа (ввод captcha).
    \item Невидимые элементы разметки,
    \item динамически формируемые страницы торговых площадок и политик безопасности,
    \item промахи при сборе данных из-за частично некорректных результатов поиска на торговых площадках и в поисковых движках.
\end{enumerate}

Проблемы 1, 2, 3 решаются использованием разных заголовков браузера попеременно. Также отправка запросов ограничена по частоте от 2 до 6 секунд, ограничение выбирается случайным образом. Такие решения позволяют крайне редко попадать под подозрения, потому что в таком случае поведение максимально похоже на поведение реального пользователя, соответственно процент успеха при попытке получить данные с веб-страницы значительно повышается. Стоит отметить, что данные ограничения очень эффективно обходятся за счет использования прокси-серверов, которые позволяют менять ip-адрес. Еще одним важным и эффективным инструментом является профиль браузера. Он позволяет запускать безголовый браузер с определенной историей использования, будь то куки-файлы, история запросов или аутентификация в различных сервисах. Наличие такой предыстории у браузера для некоторых сайтов является доказательством, что он не находится под управлением программы.

Проблема 4 решается следующим образом. Попав на страницу политики безопасности, можно исполнить код на javascript, который загрузит на страницу библиотеку для работы с деревом DOM и удалит невидимые элементы разметки.

Проблема 5 решается использованием безголового браузера, который является полнофункциональным с точки зрения воспроизведения контента, так как поддерживает исполнение javascript кода на странице. Таким образом страница будет загружена и динамические элементы будут созданы, после чего можно будет их обработать. Однако на некоторых веб-сайтах для того, чтобы получить ту или иную информацию необходимо заполнить форму. С такими обстоятельствами сложно бороться – разметка всегда различается, но таких случаев крайне мало, поэтому исключение их из рассмотрения будет оправданным.

Проблема 6 может отчасти решиться конкретизацией поискового запроса путем прибавления к названию производителя ключевых слов и продукции, которая им производится. Хотя этот вариант и показал гораздо более качественные результаты нежели чем поиск производителя <<как есть>>, иногда все же присутствует шум.

\subsection{Приложение веб-скрейпер}

\subsubsection{Первичная декомпозиция и планирование}

Начальным этапом решения задачи является первичная декомпозиция, в ее результате выделяются подзадачи различной важности, которые должны быть решены для доведения цикла разработки до конца. В данном случае можно выделить следующие подзадачи:
\begin{enumerate}
    \item определение источника информации о различной IoT-продукции,
    \item отправка поискового запроса,
    \item получение результатов запроса (список IoT-продуктов),
    \item определение производителей IoT-продукции,
    \item поиск официальных сайтов производителей в сети интернет,
    \item поиск раздела <<политика безопасности>> на сайтах производителей,
    \item скачивание политик безопасности,
    \item очистка скачанных веб-документов от лишних элементов разметки,
    \item слияние тегов и оборачивание сырого текста,
    \item нормализация пунктуации и отступов,
    \item извлечение текста из тегов.
\end{enumerate}

\subsubsection{Структура приложения веб-скрейпера}
Исходя из результатов декомпозиции, эффективным подходом выглядит представление приложения в виде последовательно выполняющихся подпрограмм так, что входом модуля является результат работы предыдуще\-го модуля, то есть в виде конвейера. Схема организации приложения представлена на рисунке \ref{fig:pipeline}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Схема организации приложения\label{fig:pipeline}}}
    {\includegraphics[width=.8\textwidth]{pics_pipeline.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Таким образом приложение построено на 4 основных концепциях.

\begin{enumerate}
    \item Концепция модуля -- одна из основополагающих, так как модулем в данном случае выступает любая подпрограмма, участвующая в сборе данных, принимающая входные данные в виде json-файла, и на выходе дающая так же json-файл, чтобы следующий в очереди модуль мог выполнить свою работу. Модули могут быть написаны с нуля, а могут расширять возможности уже существующих посредством механизма наследования. Таким образом можно не переписывая существующий код, а только добавляя новый изменять поведение программы и адаптировать ее под разные задачи сбора данных.
    \item Концепция конвейера -- этот элемент поочередно вызывает модули и передает данные из одного модуля в другой. В результате отработки всех модулей поэтапно решается поставленная задача, то есть сбор данных из интернет-источников. Конвейер может быть сконфигурирован, в него могут быть помещены любые модули, реализующие соответствующий интерфейс. Также может быть сконфигурирована последовательность запуска модулей сбора данных.
    \item Концепция поискового движка -- данная концепция порождена в связи с необходимостью сделать приложение как можно более гибким. Такой абстрактный элемент позволяет менять используемые поисковые движки, применять к результатам поиска алгоритмы для определения, какие результаты удовлетворяют условиям поиска, а какие нет.
    \item Концепция плагина -- плагин обеспечивает сбор данных с какой-либо конкретной торговой площадки. Данная концепция использована так же для обеспечения гибкости приложения -- для устранения привязки к конкретным торговым площадкам. Используя механизм наследования, можно переопределить поведение плагина для работы с любой другой торговой площадкой. 
\end{enumerate}

Далее была разработана композиционная модель приложения, на ней присутствуют все необходимые для решения задач модули. Схема представлена на рисунке \ref{fig:composition}.

На рисунке \ref{fig:composition} модуль <<main>> отвечает за запуск программы, развертывание основных ее частей. Там же происходит инициализация пула процессов для параллельного выполнения затратных задач, таких как, например, взаимодействие с <<безголовым>> браузером. Он так же отвечает за последовательное исполнение подпрограмм -- элементов конвейера. Он осуществляет прием выходных и передачу входных данных модулей.

Модуль <<initialization>> производит проверку файловой системы и создает необходимые директории в папке ресурсов.

Модуль <<tools>> содержит вспомогательные функции, в частности для ввода и вывода данных в формате json. 

Модуль <<crawler>> отвечает за получение данных с веб-страниц, в нем агрегированы все инструменты для сбора и очистки данных. 

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Композиционная модель приложения\label{fig:composition}}}
    {\includegraphics[width=\textwidth]{pics_modules.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Модуль <<plugins>> включает в себя набор плагинов, каждый из которых адаптирован для получения требуемой информации с определенного шаблона веб-страничной разметки. Некоторое поведение инкапсулировано в абстрактном плагине для увеличения <<reusability>> кода. Получая адрес на вход, данный плагин производит скачивание страницы и с помощью набора шаблонов пытается извлечь информацию. Данный модуль записывает полученную с помощью плагинов информацию в json-файл для большей прозрачности и возможности сохранения результатов между запусками приложения, например для пропуска данного этапа и использования его сохраненных результатов работы. 

Данные, полученные с помощью модулей <<products>>, <<websites>>, <<policies>>, <<downloader>>, <<sanitizer>>, <<converter>> и <<efficiency>> записывается в json-файлы для большей прозрачности и возможности сохранения результатов между запусками приложения, например при пропуске какого-либо из этапов и использования его сохраненных результатов работы. Модуль <<products>> отвечает за получение производителей IoT-продуктов. Модуль <<websites>> отвечает за получение официальных сайтов производителей. Модуль <<policies>> отвечает за получение веб-ссылок на политики безопасности. Модуль <<downloader>> отвечает за скачивание страниц и их сохранение в отведенную для этого директорию. Модуль <<sanitizer>> отвечает за очистку скачанных веб-страниц от ненужных тегов и ссылок. Модуль <<converter>> производит перевод политик безопасности из веб-страничного вида в текстовое представление. Модуль <<efficiency>> производит расчет статистики по датасету.

Модуль <<web>> отвечает за взаимодействие с вебсайтами, будь то торговые площадки или сайты производителей IoT-продуктов. В нем используется geckodriver для управления <<безголовым>> браузером. 

Модуль <<proxy>> содержит инструменты для скачивания и автоматического применения бесплатных прокси-серверов. Однако ввиду ненадежности бесплатных, есть также возможность задать список выделенных прокси-серверов. 

Для обеспечения наиболее гибкой настройки, как можно больше настроек выведено в отдельный конфигурационный файл. В нем задаются:

\begin{enumerate}
    \item параметры для библиотеки html-sanitizer, в частности набор допустимых тегов и допустимых атрибутов;
    \item параметры безголового браузера, в том числе количество повторных попыток при сбоях, появлении captcha и т.д., набор агентов пользователя для перебора, флаги использования кэширования, флаг запуска браузера в режиме без графического интерфейса, флаг использования прокси, пути для логов, а также путь до профиля браузера;
    \item список директорий и файлов, в которые происходит сохранение результатов сбора данных;
    \item количество процессов для одновременного сбора данных на многоядерных конфигурациях.
\end{enumerate}

Для настройки работы заменяемых элементов, таких как поисковые движки, плагины и модули, предусмотрены отдельные файлы, в которых создаются те или иные конфигурируемые объекты.

Учитывая конвейерную организацию и передачу результатов из модуля в модуль посредством json-файлов, структура датасета следующая: каждый модуль имеет свой json-файл для записи результатов. По сути результаты -- это массив из python-словарей, каждый словарь является своего рода кортежем, эти кортежи обладают избыточностью данных, однако, таким образом достигается максимальная простота формализации данных. Каждый элемент -- IoT устройство, обладающее набором информационных полей: идентификатор; ссылка на страницу на торговой площадке; наименование производителя; ключевое слово, по которому было найдено устройство; ссылка на сайт производителя; ссылка на политику безопасности; путь к сохраненной оригинальной страницы политики безопасности; путь к очищенной политике безопасности; путь к текстовой версии политики безопасности; хэш, сгенерированный по тексту политики; блок статистики по структурным элементам, таким как нумерованные и ненумерованные списки, элементы списков, таблицы, параграфы, длина политики в символах. Пример такой разметки можно увидеть на рисунке \ref{fig:tuple}.

В веб-скрейпере также предусмотрена возможность явного указания адресов для скачивания политик безопасности, для чего выделен отдельный json-файл, содержащий элементы со схожей структурой. В нем можно указывать любые из полей -- они будут заполнены соответствующе, а незаполненные поля останутся равными <<null>>. Явно заданные для скачивания политики считываются непосредственно на этапе скачивания, таким образом данные о названии производителя и другие данные, которые участвуют в более ранних стадиях сбора несут сугубо справочный характер. Статистические показатели политик безопасности рассчитываются на последнем этапе работы приложения, что означает их перезапись после каждого запуска, при условии, что модуль расчета статистики активен.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример кортежа датасета\label{fig:tuple}}}
    {\includegraphics[width=.9\textwidth]{tuple.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Средства разработки веб-скрейпера}
Для реализации приложения были выбраны следующие средства:
\begin{enumerate}
    \item бесплатный текстовый редактор visual studio code,
    \item система контроля версий git,
    \item python 3.9,
    \item <<безголовый>> браузер Firefox,
    \item драйвер для управления <<безголовым>> браузером <<geckodriver>>,
    \item библиотека html-sanitizer для очистки скачанных веб-документов. 
\end{enumerate}

Выбор <<безголового>> браузера обусловлен потребностью в отрисовывании страниц, так как на некоторых веб-страницах разметка генерируется с помощью javascript. Это делает невозможным использование простого скачивания, не обходима страница именно с исполненными скриптами, в противном случае будет невозможно получить требуемую информацию. В то же время браузер лишен графического интерфейса, чем снижается потребление вычислительных ресурсов. 

\subsection{Инструмент разметки датасета}
Инструмент разметки датасета планируется реализовать с помощью веб-технологий. Серверная часть будет полагаться на приложение, написанное на PHP, которое будет регулировать порядок выдачи текста на аннотирование. Процесс разметки высокодинамичен, поэтому невозможно избежать написания качественной клиентской части приложения на языке javascript. Это позволит сделать работу аннотаторов максимально производительной, в <<одну сессию>>, так как страница не будет перезагружаться. Рассматривая инструмент разметки на высоком уровне абстрагирования, можно отметить несколько основных шагов в работе приложения:
\begin{enumerate}
    \item пользователь получает текст для проведения аннотирования, который передается его клиентской части от сервера;
    \item пользователь осуществляет аннотирование:
    \begin{itemize}
        \item пользователь добавляет слои аннотирования к тексту,
        \item пользователь убирает слои аннотирования с текста;
    \end{itemize}
    \item пользователь завершает аннотирование;
    \item клиентская часть приложения формирует структуру данных, отражающую полученный результат разметки и отправляет ее на сервер;
    \item серверная часть получает структуру данных и производит ее валидацию с точки зрения соответствия заданной структуре;
    \item по завершении валидации, если структура разметки не повреждена, производится ее сохранение в базу данных.
\end{enumerate}

Приложение разделяется на три части, то есть три репозитория:
\begin{itemize}
    \item репозиторий серверной части приложения,
    \item репозиторий программы развертывания базы данных,
    \item репозиторий клиентской части приложения.
\end{itemize}

\subsubsection{Объектное моделирование приложения}

Перед непосредственно реализацией инструмента разметки было проведено моделирование на разных уровнях -- объектном и реляционном. Объектная модель предметной области представлена на рисунке \ref{fig:object}.

В соответствии с полученной реляционной моделью, ключевыми для процесса аннотирования являются 3 сущности:
\begin{itemize}
    \item <<Text>> -- текст политик безопасности, подлежащих аннотированию,
    \item <<Selection>> -- Фрагмент пользовательского аннотирования,
    \item <<SelectionClass>> -- Классификатор фрагмента аннотирования.
\end{itemize}

Сущность <<Text>> содержит исходные данные для аннотирования -- текст политики безопасности. Пользователь, производя аннотирование политики, выделяет фрагменты текста (<<Selection>>) и отмечает их как фрагменты, принадлежащие определенному классу (<<SelectionClass>>). Класс в свою очередь позволяет сформировать дерево классификации разметки, таким образом имея координаты фрагмента в тексте и дерево классификации разметки, возможны эффективный поиск и анализ размеченных текстов политик безопасности.

Сущности <<Password>>, <<User Group>>, <<Permission>> также являются необходимыми. Они не относятся непосредственно к аннотированию текстов политик, но позволяют идентифицировать аннотаторов и разграничивать доступ к тем или иным функциям инструмента аннотирования.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Объектная модель\label{fig:object}}}
    {\includegraphics[width=.7\textwidth]{models_object.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Реляционная модель приложения}

Далее на основе результатов объектного моделирования предметной области была построена реляционная модель. Реляционная модель предметной области изображена на рисунке \ref{fig:relational}.

Здесь на рисунке \ref{fig:relational} закономерными являются рекуррентные связи в отношениях <<SelectionClass>> и <<Selection>>, таким образом в реляционной модели обеспечивается построение иерархических структур, в данном случае иерархии разметки текста. В целом, при переходе от объектной модели к реляционной значительных изменений с точки зрения структуры сущностей и связей не потребовалось.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Реляционная модель\label{fig:relational}}}
    {\includegraphics[width=.9\textwidth]{models_relational.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Проектирование пользовательского интерфейса}
\label{sec:ui}

Пользовательский интерфейс инструмента разметки -- один из его ключевых компонентов. Аннотирование -- сложный, выматывающий процесс, поэтому очень важно, создать комфортные условия для пользователя. Для долгого чтения более предпочтительными являются спокойные темные тона, такие комбинации цветов является наименее раздражительными для зрительных органов. Шрифты для обеспечения совместимости были установлены в соответствии со стандартными, используемыми операционной системой пользователя.  

На рисунке \ref{fig:pics_management_add} синим цветом отмечено выделения пользователя, слева -- инструмент управления слоями разметки, который делает предложение по нанесению какого либо слоя, в рамках заданной иерархии.

На рисунке \ref{fig:pics_management_del} зеленым цветом отмечен фрагмент разметки, слева -- инструмент управления слоями разметки, который предоставляет возможность снять метку с фрагмента текста.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример добавления слоев\label{fig:pics_management_add}}}
    {\includegraphics[width=.9\textwidth]{pics_management_add.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Презентационный прототип интерфейса инструмента разметки представлен на рисунке \ref{fig:proto}. Как можно видеть по презентационному прототипу, основная идея заключается в разделении материала на 2 колонки, основная колонка содержит в себе текст политики безопасности, слева -- инструмент добавления, просмотра и удаления слоев разметки. Также в приложении предусмотрена глобальная навигация с помощью верхней панели, которая всегда присутствует на экране. В ней же кроме ссылок на страницы приложения присутствует кнопка выхода из учетной записи.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример удаления слоя\label{fig:pics_management_del}}}
    {\includegraphics[width=.9\textwidth]{pics_management_del.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Презентационный прототип интерфейса\label{fig:proto}}}
    {\includegraphics[width=.9\textwidth]{models_proto.pdf}}
    \vspace{-\baselineskip}
\end{figure}

В инструменте разметки также предусмотрены функции контроля доступа. В целом, вместе с частью приложения для разметки информационная модель приложения выглядит так, как это показано на рисунке \ref{fig:informational_model}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Информационная модель интерфейса\label{fig:informational_model}}}
    {\includegraphics[width=.95\textwidth]{pics_informational.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Результаты разработки пользовательского интерфейса представлены в разделе \ref{sec:real_proto}.

\subsubsection{Диаграммы классов инструмента разметки}

Необходимо отметить, что сами по себе построенные в предыдущих разделах модели предметной области не способны функционировать без определенных средств поддержки. Диаграмма классов серверной части приложения приведена на рисунке \ref{fig:classes_backend}. Для этого было реализовано приложение на основе шаблона проектирования MVC, которое предоставляет пользовательский интерфейс, а также реализует серверную логику инструмента разметки, тем самым связывая все программные части в единую информационную систему.  

На диаграмме классов серверной части отчетливо видна область с реализацией слоя моделей паттерна MVC. Они расположились в левой части диаграммы. Над моделями расположены контроллеры, которые отвечают за обработку запросов клиентской части. В правой части расположены многочисленные сервисы -- маленькие программные пакеты, решающие конкретные задачи, например переадресация, контроль доступа и т.д. Все сервисы работают внутри специального контейнера, обратившись к которому можно получить доступ к сервисам. Так же приложение включает в себя так называемых посредников. Они обеспечивают последовательную обработку запросов вплоть до отправки ответа клиенту.

Клиентская часть приложения для разметки состоит из трех основных частей: поверхность аннотирования, контейнер слоев разметки и панели управления слоями. Поверхность аннотирования ведет учет выделений текста. Контейнер слоев регистрирует новые слои и удаляет старые по запросу, также он предоставляет информацию о слое по его идентификатору.

\begin{figure}[H]
    \centering
    \vspace{2\baselineskip}
    \ffigbox[\FBwidth]
    {\caption{Диаграмма классов серверной части приложения\label{fig:classes_backend}}}
    {\includegraphics[width=\textwidth]{pics_classes_backend.pdf}}
    \vspace{-\baselineskip}
\end{figure}

 Панель управления слоями предоставляет пользователю возможность добавлять и удалять слои разметки, а также предоставляет информацию о слоях наложенных на те или иные фрагменты текста. Диаграмма классов клиентской части приложения приведена на рисунке \ref{fig:classes_frontend}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Диаграмма классов клиентской части приложения\label{fig:classes_frontend}}}
    {\includegraphics[width=.9\textwidth]{pics_classes_frontend.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Средства разработки инструмента разметки}
В качестве среды работы и развертывания инструмента разметки были выбраны следующие инструменты:
\begin{enumerate}
    \item visual studio code -- бесплатный текстовый редактор,
    \item git -- система контроля версий,
    \item nginx -- в качестве прокси для обращения к приложению,
    \item php7.4-fpm -- для обработки запросов от nginx и передачи их в приложение,
    \item mariadb -- в качестве СУБД базы данных.
\end{enumerate}

Для реализации инструмента разметки были выбраны следующие средства:
\begin{enumerate}
    \item php 7.4 -- как язык написания серверной части приложения,
    \item composer -- пакетный менеджер php,
    \item javascript стандарта ES6 -- для разработки клиентской части приложения,
    \item webpack -- инструмент для сборки клиентской части,
    \item bootstrap -- библиотека для создания пользовательских интерфейсов.
\end{enumerate}

Данный стек технологий был выбран в соответствии с потребностями для разработки инструмента разметки политик безопасности и полностью их удовлетворяет.

\subsection{Результаты этапа проектирования инструментария}
Подводя итог раздела, посвященного проектированию инструментария для формализации политик безопасности, можно отметить, что вся необходимая подготовительная работа была проведена успешно, были предложены методики для сбора, очистки и разметки текстов политик безопасности. Так же было проведено непосредственное проектирование веб-скрейпера и инструмента разметки, включающее в себя рассмотрение потенциальных проблем, которые могут возникнуть на этапе реализации, моделирование программного решения на разных уровнях с применением универсального языка моделирования UML, а также выбор программных средств реализации.

\newpage
\section{Результаты реализации инструментария}

\subsection{Полученные в результате реализации исходные коды}
В соответствии с результатами декомпозиции, выбора средств и проектирования приложение было реализовано. Исходные коды представлены в приложениях \hyperref[sec:appendix1]{А} и \hyperref[sec:appendix2]{Б}.

\subsection{Полученный в результате сбора данных датасет}
Поиск IoT-продуктов осуществлялся на торговых площадках Amazon и Walmart, брались результаты поискового запроса по первым 30-ти страницам, по категориям <<smart scale>>, <<smart watch>>, <<smart bracelet>>, <<smart lock>>, <<smart bulb>>, <<smart navigation system>>, <<smart alarm clock>>, <<smart thermostat>>, <<smart plug>>, <<smart light switch>>, <<smart tv>>, <<smart speaker>>, <<smart thermometer>>, <<smart air conditioner>>, <<smart video doorbell>>, <<robot vacuum cleaner>>, <<smart air pu\-ri\-fi\-er>>, <<gps tracking device>>, <<tracking sensor>>, <<tracking device>>, <<indoor came\-ra>>, <<outdoor camera>>, <<voice controller>>. Всего производителей было найдено приблизительно 160. Стоит отметить, что результат является приемлемым, так как многие производители на данных торговых площадках не имеют выделенного вебсайта, а пользуются услугами Amazon, то есть на таких страницах действует политика безопасности Amazon, а не производителя. Также стоит отметить, что у некоторых продуктов явно не указан производитель, что количественно сократило результат поиска.

Всего было проанализировано 57150 моделей умной продукции, из них для 51727 (90,5\%) были определены производители. Всего уникальных производителей было найдено 6161, из них 1419 (23\%) имеют официальную веб-страницу. Проанализировав найденные веб-сайты были собраны 798 политик безопасности, разумеется, среди них имеется определенный процент промахов, если производитель имеет сходство с каким-либо другим более крупным. Из датасета были исключены политики безопасности, длина которых в символах не превышала 1000. Это объясняется тем, что некоторые производители имеют на своем сайте страницу с политикой безопасности, но по каким-то причинам эта страница не наполнена. Примеры таких случаев приведены на рисунках \ref{fig:not_found1} и \ref{fig:not_found2}. Таким образом полноценных уникальных политик безопасности осталось 592.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример отсутствующей политики\label{fig:not_found1}}}
    {\includegraphics[width=.9\textwidth]{not_found1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Некоторые из производителей, которые не имеют собственного веб-сайта и политика безопасности которых не была найдена, пользуются услугами хостинга интернет-магазина непосредственно на Amazon. В таком случае, будучи частью интернет-магазина на них распространяется политика безопасности площадки, на которой они размещают свои предложения, причем политики могут различаться для разных стран.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример отсутствующей политики\label{fig:not_found2}}}
    {\includegraphics[width=.9\textwidth]{not_found2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

 Случаи с использованием отдельных политик безопасности под различные типы устройств не были зафиксированы, хотя такие случаи и существуют, проще прибегнуть к явному заданию адресов политик, нежели чем к попытке автоматизировать процесс сбора, так как остаются непрозрачными способы выявления подобных ситуаций.

На рисунках \ref{fig:paragraph_size} и \ref{fig:policy_size} приведены статистические данные по объемам абзацев политик и самих документов соответственно.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение политик по объему параграфа\label{fig:paragraph_size}}}
    {\includegraphics[width=.7\textwidth]{paragraph_size.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение политик по объему документа\label{fig:policy_size}}}
    {\includegraphics[width=.7\textwidth]{policy_size.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Подсчет количества заголовков сложно организовать автоматизированно в связи с большим разнообразием html-разметки. На каждом сайте своя разметка, своя конвенция по нумерованию секций, заголовков, списков. На некоторых сайтах списки и заголовки нумеруются средствами html, на других нумерация проставлена вручную. Все это порождает разношерстность данных, и их обработка становится сложной с точки зрения учета всех возможных вариантов. Поэтому авторы решили прибегнуть к простому подсчету длин строк длиной меньше 100 символов и не содержащих при этом маркеров <<{list item}>>. Такой подход не даст очень точных показателей, но может дать приблизительные значения. На рисунках \ref{fig:structure_stats1} и \ref{fig:structure_stats2} приведена статистика по структурным элементам политик безопасности в двух частях. Здесь изображены детальные распределения структурных элементов для каждой из найденных политик безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика первых 246 политик в IoT-датасете по структурным элементам\label{fig:structure_stats1}}}
    {\includegraphics[width=\textwidth]{structure_stats1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика последних 246 политик в IoT-датасете по структурным элементам\label{fig:structure_stats2}}}
    {\includegraphics[width=\textwidth]{structure_stats2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Таким образом можно описать среднестатистическую политику безопасности, которая состоит из 31.5 абзацев, 33 заголовков, 23.6 элементов перечислений, 0.7 нумерованных списков, 4.4 ненумерованных списка, 0.5 таблиц.

Для дополнительного статистического анализа датасета, он был кластеризован с помощью латентного размещения Дирихле. Как и в предыдущих разделах для кластеризации политики безопасности были разбиты на абзацы, после чего была проведена предобработка, состоящая из лемматизации, удаления пунктуации и так называемых стоп-слов. В таблице \ref{tab:iot_clusters} приведены результаты моделирования тем в IoT-датасете. В предыдущих разделах уже была исследована точность латентного размещения Дирихле, его преимущества и недостатки, на основании чего IoT-датасет был проанализирован именно таким способом. По результатам видно, что с помощью такой кластеризации можно выделить различные аспекты политик безопасности.

\begin{ltwrap}{2mm}{1.7}{\footnotesize}
    \begin{longtable}[H]{|C{.05\x}|M{.475\x}|M{.475\x}|}
        \caption{Тематическое моделирование\label{tab:iot_clusters}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.475\x}|}{Координаты семантического пространства} 
        & \multicolumn{1}{H{.475\x}|}{Возможные сценарии использования}\\\hline
        \endfirsthead
        \caption*{Продолжение таблицы \ref{tab:iot_clusters}}\\\hline
        \multicolumn{1}{|H{.05\x}|}{№}
        & \multicolumn{1}{H{.475\x}|}{Координаты семантического пространства} 
        & \multicolumn{1}{H{.475\x}|}{Возможные сценарии использования}\\\hline
        \endhead
        \endfoot
        \endlastfoot
        0 & email, send, promotional, communication, marketing, opt, product, service, message, list & First-party collection, Opt-in, opt-out messages and notifications to end user \\\hline
        1 & party, third, service, information, privacy, website, share, policy, site, advertising & Third parties sharing for marketing purposes \\\hline
        2 & removed, href, hyperref, question, contact, privacy, us, please, policy, comment & Contact information: company \\\hline
        3 & cookie, device, browser, service, address, website, site, collect, information, use & First-party collection: browser and device information \\\hline
        4 & child, age, entering, detection, year, fill, redirected, show, knowingly & Special audience: children \\\hline
        5 & sensor, educational, suggestion, top, acquirer, mailing, employment, job, taking, clickstream & First-party collection: device and service specific information \\\hline
        6 & corporate, automated, storefrontdigest, indefinite, personalization, direction, administrator, token, shop, employed & Other \\\hline
        7 & data, personal, right, request, processing, information, necessary, legal, purpose, law & First-party collection: right to edit, access, with specified (legal) basis of data processing \\\hline
        8 & sponsor, push, reply, default, swiss, desire, becoming, correspondence, calling, representative & Other \\\hline
        9 & asset, service, product, merger, company, item, list, business, another, referral & Third-party sharing in case of company acquisition and merging \\\hline
        10 & erasure, unaffiliated, input, approximate, format, appliance, pref, persistent, canadian, short & Right to erase \\\hline
        11 & address, name, information, account, email, promotion, password, u, collect, contact & First-party collection: personal and account information \\\hline
        12 & security, protect, safety, hosted, secure, violate, property, others, technical, law & Data security \\\hline
        13 & california, state, resident, institution, law, united, ccpa, right, request, country & Special audience: California residents \\\hline
        14 & change, policy, privacy, statement, time, notice, pci, payment, ds, update & Privacy policy changes \\\hline
    \end{longtable}
\end{ltwrap}

При кластеризации порог аффилиации абзаца политики безопасности был установлен в 0.3, параграф относился к нескольким кластерам, если вероятность аффилиации с ним была больше указанного порога. По графику на рисунке \ref{fig:topics_stats} можно судить, какую часть от общего объема текстов занимают те или иные аспекты политик безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика аспектов в IoT-датасете\label{fig:topics_stats}}}
    {\includegraphics[width=.8\textwidth]{topics_stats.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Как заключение статистического обзора сформированного датасета на рисунках \ref{fig:topics_stats1} и \ref{fig:topics_stats2} приведено детальное распределение аспектов политик безопасности по каждой конкретной политике.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика первых 246 политик в IoT-датасете по аспектам\label{fig:topics_stats1}}}
    {\includegraphics[width=\textwidth]{topics_stats1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика последних 246 политик в IoT-датасете по аспектам\label{fig:topics_stats2}}}
    {\includegraphics[width=\textwidth]{topics_stats2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Здесь в виде гистограммы представлены распределения всех 15 аспектов, выделенных алгоритмом LDA. Каждый абзац может относиться к нескольким аспектам с порогом аффилиации 0.3.

\subsection{Полученный в результате реализации инструмент разметки}
\label{sec:real_proto}

В ходе реализации был разработан инструмент разметки датасета. На рисунках \ref{fig:init_annotation}--\ref{fig:result2} представлен его конечный вид. В качестве тестового примера была взята часть онтологии, предложенной в \cite{P2Onto}, и посвященной описанию активности по отношению к персональным данным. Инструмент был настроен для работы с указанной частью онтологии. Выделения и нанесенная разметка в данных примерах не являются осмысленными и выполнялись исключительно с целью демонстрации работоспособности приложения.

На рисунке \ref{fig:init_annotation} представлено начальное состояние страницы разметки. В начальном состоянии панель инструментов не показывает ни одного слоя, текст для разметки представлен в первоначальном виде.

На рисунке \ref{fig:selection} представлена реакция инструмента на выделение текста пользователем. При выделении пользователем текста на панели слоев закрепляются слои доступные для наложения, выбранные контекстуально, в соответствии с настроенной иерархией разметки.
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Начальное состояние страницы разметки\label{fig:init_annotation}}}
    {\includegraphics[width=.8\textwidth]{ui/init_annotation.pdf}}
    \vspace{-\baselineskip}
\end{figure}
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Выделение текста\label{fig:selection}}}
    {\includegraphics[width=.8\textwidth]{ui/selection.pdf}}
    \vspace{-\baselineskip}
\end{figure}

На рисунке \ref{fig:annotated1} представлено состояние страницы разметки после нанесения слоя разметки. Теперь панель слоев отображает текущие наложенные слои для элемента, на который наведен указатель мыши.
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Нанесение слоя разметки\label{fig:annotated1}}}
    {\includegraphics[width=.8\textwidth]{ui/annotated1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

На рисунке \ref{fig:selection2} представлена реакция инструмента на выделение текста пользователем. Теперь контекстуально на основе информации о наложенных слоях, предлагаются слои другого уровня детализации.
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Выделение размеченного текста\label{fig:selection2}}}
    {\includegraphics[width=.8\textwidth]{ui/selection2.pdf}}
    \vspace{-\baselineskip}
\end{figure}

На рисунке \ref{fig:result1} представлено состояние страницы разметки после нанесения нескольких неконфликтующих слоев разметки.
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Нанесение нескольких слоев\label{fig:result1}}}
    {\includegraphics[width=.8\textwidth]{ui/result1.pdf}}
    \vspace{-\baselineskip}
\end{figure}

На рисунке \ref{fig:result2} представлено состояние страницы разметки после удаления одного из слоев разметки. Поверхность аннотирования осуществляет поиск одинаковых по составу слоев разметки и производит их слияние, так что фрагменты с одинаковым набором слоев выглядят целостно.
\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Удаление слоя\label{fig:result2}}}
    {\includegraphics[width=.8\textwidth]{ui/result2.pdf}}
    \vspace{-\baselineskip}
\end{figure}


\subsection{Итоги этапа реализации}
Подводя итоги раздела, посвященного реализации инструментария для формализации политик безопасности, можно отметить, что на данном этапе были успешно получены программные коды всех компонентов инструментария. С помощью разработанного веб-скрейпера с модульной архитектурой был произведен сбор политик безопасности из открытых источников, а именно 592 политики безопасности производителей IoT-устройств. Были подробно рассмотрены статистические и структурные особенности политик безопасности. Полученный датасет имеет ряд преимуществ по сравнению с существующими датасетами, например из работы \cite{MDPI18}, так как он был сформирован в 2021 году, после принятия GDPR в качестве основного международного документа по защите персональных данных. Также датасет является одним из немногих по его тематической ориентации на IoT-устройства. В соответствии с планом по реализации был разработан инструмент разметки текстов политик безопасности для построения обучающей выборки, результат его работы был также представлен.

\newpage
\section{Составление бизнес-плана по коммерциализации результатов научно-исследовательской работы магистра}

\subsection{Результаты составления бизнес-плана по коммерциализации результатов научно-исследовательской работы магистра}
В заключение раздела, посвященного составлению бизнес-плана по коммерциализации результатов научно-исследовательской работы магистра стоит упомянуть, что отличительные особенности разработанных продуктов и полученного датасета, позволяют проекту составить конкуренцию на рынке, чему также способствуют научная база работы и продуманное программное обеспечение.

\end{document}