%!TEX root = ../main.tex
\documentclass[../main]{subfiles}

\begin{document}

% \footnotesize
% \begin{longtable}[H]{|c|c|c|c|c|c|}
%     \caption{Групповая матрица попарных сравнений <<Стоимость про\-из\-вод\-ства>>\label{tab:gmanufacture_cost}}\\\hline
%     \multicolumn{1}{|c|}{\makebox[1.5cm]{$E   $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{5}  $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{8}  $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{18} $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{19} $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{20} $}} \\\hline
%     \endfirsthead
%     \caption*{Продолжение таблицы \ref{tab:gmanufacture_cost}}\\\hline
%     \multicolumn{1}{|c|}{\makebox[1.5cm]{$E   $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{5}  $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{8}  $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{18} $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{19} $}} &
%     \multicolumn{1}{c|} {\makebox[1.5cm]{$S_{20} $}} \\\hline
%     \endhead
%     \endfoot
%     \endlastfoot
%     $S_{5}  $ & $1.00$ & $6.70$ & $8.49$ & $0.21$ & $2.45$ \\\hline
%     $S_{8}  $ & $0.15$ & $1.00$ & $0.35$ & $0.15$ & $0.31$ \\\hline
%     $S_{18} $ & $0.12$ & $2.83$ & $1.00$ & $0.12$ & $1.00$ \\\hline
%     $S_{19} $ & $4.73$ & $6.74$ & $8.21$ & $1.00$ & $6.96$ \\\hline
%     $S_{20} $ & $0.41$ & $3.22$ & $1.00$ & $0.14$ & $1.00$ \\\hline
% \end{longtable}
% \normalsize

% \begin{landscape}
%     \begin{figure}[H]
%         \centering
%         \ffigbox[\FBwidth]
%         {\caption{Иерархия критериев\label{fig:hierarchy}}}
%         {\includegraphics[width=\textwidth]{pic.pdf}}
%         \vspace{-14pt}
%     \end{figure}
% \end{landscape}


\newpage
\section{Анализ предметной области}

\subsection{Обзор текущего состояния предметной области}
Текст\dots

\subsection{Методика формализации политик безопасности с применением онтологического представления предметной области}
Текст\dots

\subsection{Статистические модели текстовых документов}

Были протестированы две модели векторизованного представления текста -- <<мешок слов>> и модель TF-IDF. Модель <<мешок слов>> представляет документ в виде матрицы, представленной на рисунке \ref{fig:bow}. Здесь слова каждого абзаца подсчитываются и сопоставляются с абзацами, в которых они встретились.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Bag-of-Words матрица\label{fig:bow}}}
    {\includegraphics[width=.7\textwidth]{bow.pdf}}
    \vspace{-\baselineskip}
\end{figure}


Модель TF-IDF представляет документ в виде матрицы, представленной на рисунке \ref{fig:tfidf}. Формула (\ref{eq:tfidf}) показывает, как можно получить метрику TF-IDF.
\begin{equation}
    \label{eq:tfidf}
    tfidf(t, d, D) = \frac{n_t}{\displaystyle\sum_k n_k} \times 
    log \frac{ \big|{D}\big| }
    { \big|\left\{ d_i \in D : t \in d_i \right\}\big| }\ ,
\end{equation}
\makebox[12.5mm]{где\hfill}$t$ -- термин или слово;\\
\makebox[12.5mm]{}$d$ -- конкретный абзац;\\
\makebox[12.5mm]{}$D$ -- набор абзацев. 

Итак, модель TF-IDF придает больший вес словам которые использованы меньше раз. Это может быть полезно, когда тексты схожи с точки зрения используемых слов, как в нашем случае, для политик безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Матрица TF-IDF\label{fig:tfidf}}}
    {\includegraphics[width=.7\textwidth]{tfidf.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsection{Подход основанный на латентно-семантическом анализе текста}

Современные методы кластеризации текстов позволяют определять тематику текстов с высокой точностью. Однако большинство из этих методов принимают тексты с самыми разными темами как вход для алгоритмов. Но тексты со схожими тематиками можно проанализировать с помощью ла\-тен\-тно-семантического анализа дважды: группировать тексты по темам один раз, и предоставить еще более детальное разделение их по подтемам во второй раз. Такой подход можно использовать для более точной классификации абзацев с точки зрения их характеристик и аспектов использования персональных данных. Следует отметить, что латентно-семантический поиск сильно зависит от глобального текстового контекста с потерями информации о локальных контекстных отношениях между словами. Были выделены девять тем конфиденциальности, которые следует сопоставить с абзацами согласия пользователя сайта -- <<сбор личных данных>>, <<сбор данных третьими лицами>>, <<управление личными данными>>, <<механизмы защиты персональных данных>> и др. Очевидно, что аспекты обращения с данными состоят из нескольких слов, и в некоторых случаях перекрываются. На основании этих фактов была выдвинута гипотеза о том, что латентно-семантический поиск способен обнаружить даже незначительную разницу в тексте абзацев при пропуске частых слов. Перед применением латентно-семантического анализа требуется предварительная обработка входных данных. Обычно эта процедура включает очистку данных, удаление гиперссылок, пунктуации и т. д. Также текст политик конфиденциальности был разбит на набор абзацев. Каждый абзац был преобразован в массив слов, которые он содержит. Следующим шагом было удаление наиболее частых, но не столь значимых слов, так называемых стоп-слов. Также была применена операция стемминга, чтобы рассматривать только основную часть всех слов полученных от единого корня.

Пусть A -- это матрица абзацев и слов, тогда используя формулу (\ref{eq:lsa})
\begin{equation}
    \label{eq:lsa}
    A = U \times S \times V^T,
\end{equation}
\makebox[12.5mm]{где\hfill}$A$ -- матрица слов и параграфов;\\
\makebox[12.5mm]{\hfill}$U$ -- ортонормированная матрица $U$;\\
\makebox[12.5mm]{\hfill}$V$ -- ортонормированная матрица $V$;\\
\makebox[12.5mm]{\hfill}$S$ -- диагональная матрица $S$, значения которой сингулярны для $A$.

После того, как матрица была разделена на три компонента, матрица $U$ содержит $n$-мерные векторы, которые можно интерпретировать как координаты в $n$-мерном пространстве \cite{LSA}. Документы могут быть распределены по кластерам по значениям этих координат. Проведенные эксперименты с латентно-семантическим анализом выполнялись с использованием набора данных с открытым исходным кодом, который включает 115 политик безопасности, которые были размечены вручную, и все абзацы присвоены одному или нескольким сценариям использования персональных данных \cite{OPP}. Результаты экспериментов для модели <<мешок слов>> представлены в таблице \ref{tab:clusters1}, в ней показаны полученные кластеры и соответствующие значения координат.

\begin{longtable}[H]{
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c|}
    \caption{Кластеры политик безопасности для модели Bag-of-Words\label{tab:clusters1}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{c|}{Coordinate 1} & 
    \multicolumn{1}{c|}{Coordinate 2} & 
    \multicolumn{1}{c|}{Coordinate 3} & 
    \multicolumn{1}{c|}{Coordinate 4} \\
    \hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:clusters1}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{c|}{Coordinate 1} & 
    \multicolumn{1}{c|}{Coordinate 2} & 
    \multicolumn{1}{c|}{Coordinate 3} & 
    \multicolumn{1}{c|}{Coordinate 4} \\
    \endhead
    \endfoot
    \endlastfoot
    0 & 0.634”inform”  & 0.28”may”        & 0.276”use”     & 0.232”servic”   \\\hline
    1 & 0.202“cooki”   & 0.466“inform”    & 0.336“site”    & 0.257“use”      \\\hline
    2 & 0.524“privaci” & 0.433“polici”    & 0.388“cooki”   & 0.219“site”     \\\hline
    3 & -0.589“servic” & 0.344“site”      & 0.244“parti”   & -0.240“third”   \\\hline
    4 & -0.504“parti”  & 0.486 “third”    & -0.449“servic” & 0.235“advertis” \\\hline
    5 & -0.594“site”   & 0.278“cooki”     & 0.272“websit”  & 0.264“privaci”  \\\hline
    6 & -0.326“may”    & 0.311“site”      & 0.307“servic”  & -0.293”email”   \\\hline
    7 & -0.437”may”    & -0.369”advertis” & 0.345”person”  & 0.319”cooki”    \\\hline
    8 & 0.501”may”     & -0.315”email”    & -0.281”use”    & -0.264”address” \\\hline
    9 & -0.488”user”   & -0.384”use”      & 0.310”provid”  & -0.301”websit”  \\\hline
\end{longtable}

Как видно, результаты противоречивы, поэтому трудно понять, какая из тем каким смыслом обладает. Затем рассчитывалась метрика принадлежности к теме с помощью библиотеки Gensim \cite{Gensim} и результаты снова не были обнадеживающими. Результаты расчета метрики принадлежности кластеру представлены в таблице \ref{tab:affiliation_bow1}.

\begin{longtable}[H]{
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c|}
    \caption{Принадлежность кластерам\label{tab:affiliation_bow1}}\\\hline
    \endfirsthead
    \endhead
    \endfoot
    \endlastfoot
    Topic       & 0     & 1     & 2    & 3     & 4     \\\hline
    Affiliation & 2.27  & -0.8  & 0.15 & -0.22 & -1.2  \\\hline
    Topic       & 5     & 6     & 7    & 8     & 9     \\\hline
    Affiliation & -0.17 & -0.15 & -0.2 & 0.22  & -0.07 \\\hline
\end{longtable}

Другие результаты с параграфами, относящимися к другому аспекту обращения с данными, были почти такими же. Результаты
представлены в таблице \ref{tab:affiliation_bow2}.

\begin{longtable}[H]{
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c|}
    \caption{Принадлежность кластерам\label{tab:affiliation_bow2}}\\\hline
    \endfirsthead
    \endhead
    \endfoot
    \endlastfoot
    Topic       & 0    & 1     & 2    & 3    & 4    \\\hline
    Affiliation & 2.59 & -0.76 & 0.64 & 0.74 & 0.13 \\\hline
    Topic       & 5    & 6     & 7    & 8    & 9    \\\hline
    Affiliation & 0.14 & -0.12 & 0.23 & 0.12 & 0.41 \\\hline
\end{longtable}

Все протестированные абзацы были сопоставлены с кластером 0, что не может быть верным так как абзацы относились к заведомо разным аспектам обращения с персональными данными. 

Результаты экспериментов для модели TF-IDF представлены далее, в таблице \ref{tab:clusters2}. Также показывались десять кластеров и значения атрибутов. И, как в первом случае с <<мешком слов>>, по значениям координат невозможно судить о теме кластера.

\begin{longtable}[H]{
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c
    |>{\setstretch{1}}c|}
    \caption{Кластеры политик безопасности для модели Bag-of-Words\label{tab:clusters2}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{c|}{Coordinate 1} & 
    \multicolumn{1}{c|}{Coordinate 2} & 
    \multicolumn{1}{c|}{Coordinate 3} & 
    \multicolumn{1}{c|}{Coordinate 4} \\
    \hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:clusters2}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{c|}{Coordinate 1} & 
    \multicolumn{1}{c|}{Coordinate 2} & 
    \multicolumn{1}{c|}{Coordinate 3} & 
    \multicolumn{1}{c|}{Coordinate 4} \\
    \endhead
    \endfoot
    \endlastfoot
    0 & 0.202“cooki”     & 0.2“may”        & 0.198“inform”   & 0.198“site”     \\\hline
    1 & 0.573“cooki”     & 0.262“browser”  & 0.195“advertis” & 0.182“web”      \\\hline
    2 & -0.406“media”    & 0.291“cooki”    & 0.282“health”   & 0.279“advertis” \\\hline
    3 & -0.453“health”   & 0.258“email”    & -0.204“kaleida” & 0.191“address”  \\\hline
    4 & 0.423“health”    & 0.215“media”    & 0.205“kaleida”  & -0.199“secur”   \\\hline
    5 & -0.299“advertis” & 0.262“health”   & -0.252“media”   & -0.213“privaci” \\\hline
    6 & -0.325“media”    & 0.263“polici”   & 0.249“privaci”  & 0.197”chang”    \\\hline
    7 & 0.280”cooki”     & -0.216”device”  & -0.183”health”  & -0.166”social”  \\\hline
    8 & -0.223”advertis” & -0.206”teenag”  & -0.206”inelig”  & 0.176”child”    \\\hline
    9 & -0.263” child”   & -0.26”wireless” & 0.245”message”  & 0.239”parent”   \\\hline
\end{longtable}

Результаты кластеризации снова противоречивы, поэтому трудно сказать, какая конкретная тема описывает какой аспект политики конфиденциальности. В разных темах встречаются одни и те же слова с изменение веса. Для аспектов политики конфиденциальности, которые мы искали нет тем, которые могли бы их точно описать, поскольку многие из них могут. Затем с помощью библиотеки Gensim был рассчитан показатель принадлежности к теме, и результаты снова не были обнадеживающими. Результаты расчета аффилированности по абзацу одной из политик конфиденциальности представленные в таблице \ref{tab:affiliation_tfidf1}.

\begin{spacing}{1.15}
\begin{longtable}[H]{|c|c|c|c|c|c|}
    \caption{Принадлежность кластерам\label{tab:affiliation_tfidf1}}\\\hline
    \endfirsthead
    \caption*{Продолжение таблицы\ref{tab:affiliation_tfidf1}}\\\hline
    \endhead
    \endfoot
    \endlastfoot
    Topic       & 0    & 1     & 2     & 3     & 4     \\\hline
    Affiliation & 2.18 & -0.97 & -0.69 & -0.27 & 0.65  \\\hline
    Topic       & 5    & 6     & 7     & 8     & 9     \\\hline
    Affiliation & 0.98 & -1.17 & 0.8   & 0.27  & 0.01  \\\hline
\end{longtable}
\end{spacing}

Результат для другого абзаца, относящегося к другой политике конфиденциальности, был почти такой же. Результаты представлены в таблице \ref{tab:affiliation_tfidf2}.

\begin{spacing}{1.15}
\begin{longtable}[H]{|c|c|c|c|c|c|}
    \caption{Принадлежность кластерам\label{tab:affiliation_tfidf2}}\\\hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:affiliation_tfidf2}}\\\hline
    \endhead
    \endfoot
    \endlastfoot
    Topic       & 0    & 1    & 2     & 3     & 4     \\\hline
    Affiliation & 1.82 & 0.25 & 0.49  & 0.29  & -0.04 \\\hline
    Topic       & 5    & 6    & 7     & 8     & 9     \\\hline
    Affiliation & 0.74 & 0.52 & -0.04 & -0.58 & -1.33 \\\hline
\end{longtable}
\end{spacing}

Как можно заметить, результаты для модели TF-IDF аналогичны результатам модели <<мешка слов>>, за исключением нескольких незначительных изменений. Все абзацы снова были сопоставлены с кластером 0, что неверно, потому что они на самом деле описывают разные сценарии использования персональных данных. Эти эксперименты позволили сделать вывод, что использование латентно-семантического анализа не дает ценной информации о содержании онлайн-согласия пользователя. Проблема может быть связана с тем, что сценарии использования персональных данных очень похожи между собой, и для того, чтобы различать разные сценарии необходимо учитывать локальный контекст.

В результате апробации алгоритма латентно-семантического анализа было выяснено что для кластеризации экстремально схожих между собой текстов он  подходит не лучшим образом. В связи с этими обстоятельствами было решено обратить внимание на несколько иной подход анализа текста, основанный на контекстно-свободных грамматиках, тегировании по частям речи и синонимическом поиске.

\subsection{Подход основанный на латентном размещении Дирихле}
Для тестирования подхода авторы использовали два набора данных. Первый набор данных – это OPP-115 с открытым исходным кодом, а второй – это набор данных, созданный авторами и состоящий из политик конфиденциальности только для устройств IoT [12].

Набор данных OPP-115 содержит 115 документов с онлайн-согласиями пользователей веб-сайта. Этот набор данных содержит аннотации сценариев использования личных данных, его авторы обозначили 10 аспектов использования личных данных: “First-party Collection/Use”, “Third-party Sharing/Col\-lec\-ti\-on”, “User Choice/Control”, “User Access, Edit and Deletion”, “Data Re\-ten\-ti\-on”, “Data Security”, “Policy Change”, “Do Not Track”, “International and Specific Audiences”, “Other”. В большинстве случаев аспекты относятся к абзацам текста, а некоторые абзацы относятся к нескольким категориям одновременно. На рисунке 1 показано распределение абзацев по категориям. Хорошо видно, что есть две основные категории – “Third-party Sharing/Collection” и “First-party Collection and Use”, которые преобладают над остальными.

Чтобы применить LDA к анализу политики конфиденциальности, мы разбили текст политики конфиденциальности на набор абзацев. Каждый абзац был преобразован в массив слов, а затем удалены наиболее частые, но не значащие слова, так называемые «стоп-слова». Мы также выполнили лемматизацию, чтобы обобщить некоторые слова, чтобы добиться более точных результатов.

В ходе экспериментов мы протестировали две модели векторизатора текста – мешок слов и TF-IDF, и оказалось, что метрика TF-IDF предоставляет более подробную информацию о сценариях использования данных, поскольку эта модель векторизатора дает более высокие веса словам, которые реже используются.

Оптимальное количество кластеров, то есть семантических моделей, было определено как 15, поскольку оно соответствует максимальному значению когерентности, рассчитанному с помощью библиотеки Gensim [13]. Важно отметить, что это число отличается от числа категорий, обозначенных создателями набора данных OPP-115.

Результаты экспериментов для модели TF-IDF показаны в таблице 1. В таблице 1 приведен список координат, которые формируют семантические модели темы. Координаты используются для составления гипотезы об использовании личных данных и сценариях его применения/политики конфиденциальности.

Хорошо видно, что большинство извлеченных моделей посвящено сценариям “First-Party Collection and Use” и “Third-Party Sharing/Collection”. Это полностью соответствует распределению категорий в наборе данных. Эти модели различаются характеристиками различных аспектов этих двух сценариев использования. Например, тематическая модель 9 раскрывает варианты согласия / отказа при обмене личными данными в рекламных целях, тематическая модель 6 посвящена использованию файлов cookie первыми и третьими сторонами, некоторые тематические модели предоставляют информацию о типах собираемых личных данных: информация об учетной записи пользователя (тематическая модель 7), финансовые данные (тематическая модель 2), данные отслеживания местоположения и аналитики (тематическая модель 11). Некоторые темы, такие как тематические модели 4 и 10, раскрывают довольно специфические аспекты использования личных данных, такие как безопасность данных, включая случай, когда данные передаются третьим лицам, и уведомление в случае изменения политики. Некоторые тематические модели являются довольно общими, например, модели характеризуют очень общие проблемы, связанные со сбором данных первой стороной и сторонним совместным использованием 0,1 и 3.

\begin{longtable}[H]{
    |c
    |>{\setstretch{1}}m{.44\textwidth}
    |>{\setstretch{1}}m{.44\textwidth}|}
    \caption{Тематическое моделирование\label{tab:affiliation_tfidf2}}\\\hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:affiliation_tfidf2}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Координаты семантического пространства} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Возможные сценарии использования} \\\hline
    \endhead
    \endfoot
    \endlastfoot
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Координаты семантического пространства} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Возможные сценарии использования} \\\hline
    0 & service, friend, story, child, cookie, use, product, email, compromised, card & First-party collection \& usage (usage of cookies, e-mail), Special audience (children) \\\hline
    1 & schedule, channel, analytic, happy, website, gather, address, mingle, moreover, identifiable & First-party collection (identifiable user data) \\\hline
    2 & collect, credit, card, us, address, pursuant, email, service, personal, may & First-party collection: payment credentials \\\hline
    3 & state, united, asset, website, policy, personal, privacy, party, third, sm & Third-party sharing \\\hline
    4 & security, personal, rating, site, u, disclosure, service, policy, physical, third & Data security (including third-party sharing)  \\\hline
    5 & party, third, child, service, cookie, personal, personally, site, company, identifiable & Third-party sharing (usage of cookies) \\\hline
    6 & service, website, personal, site, cookie, party, third, data, use, us & First-party collection \& Third-party sharing (for: services provision, usage of website data and cookies) \\\hline
    7 & personal, service, account, information, site, device, u, may, provide, use & First-party collection: user account information \\\hline
    8 & device, resume, message, policy, privacy, social, service, site, website, networking & Other \\\hline
    9 & opt, collect, site, third, advertising, personal, party, service, u, privacy & First-party collection \& Opt-in, opt-out for advertising \\\hline
    10 & military, change, policy, time, site, web, page, privacy, cookie, post & Privacy policy change, including notification mechanism \\\hline
    11 & navigating, service, google, non, adsense, nielsen, account, collect, device, privacy & First-party collection: device and location information \\\hline
    12 & station, feedback, service, consented, java, script, merchant, cookie, child, st & Other \\\hline
    13 & cookie, service, third, party, site, website, california, flash, use, technology & Third-party sharing \& Special audience: California residents \\\hline
    14 & child, forum, trade, age, pii, conversation, chat, branded, personal & Special audience: children \\\hline
\end{longtable}

Однако необходимо учитывать, что политики конфиденциальности в большинстве случаев являются очень общими и неструктурированными, они не содержат четкой спецификации действий по обработке данных. Для некоторых тематических моделей было сложно определить аспекты сценариев использования, мы назвали их “Other”.

Также стоит отметить, что не существует моделей, посвященных хранению данных и аспектам доступа, редактирования и удаления данных. Это могло произойти из-за того, что количество абзацев, содержащих эту информацию, невелико, и они семантически довольно близки к сценарию первичного сбора. В отличие от них мы обнаружили проблемы, посвященные аспектам “International and Special Audience”, “Data Security” и “Privacy Policy Change”, хотя количество вхождений в наборе данных сопоставимо с “Data Retention” и “User Access, Edit and Deletion”.

Второй набор данных состоит из почти 600 политик конфиденциальности поставщиков устройств Интернета вещей [12]. Интересно, что оптимальное количество моделей также было определено как 15. Хотя извлеченные модели были довольно похожи, однако они содержали некоторые дополнительные детали. Как и в предыдущем случае, основная часть политик конфиденциальности посвящена использованию файлов cookie и настроек веб-браузера в сценариях сбора данных и сторонними организациями. Вторая тематическая модель, которая также широко представлена в политиках конфиденциальности, также касается first-party collection но с четко обозначенной основой обработки данных. В отличие от тематических моделей, построенных для набора данных OPP-115, существуют две тематические модели, посвященные праву доступа, редактирования и удаления данных. Этот факт можно объяснить, с одной стороны, большим размером набора данных, а с другой стороны, изменениями в законодательных положениях, которые были приняты недавно и посвящены правам субъекта данных. Данные OPP-115 были созданы в 2016 году до принятия GDPR [1], а набор данных политик конфиденциальности IoT был создан в этом году, и многие компании изменили свои политики конфиденциальности, чтобы соответствовать требованиям GDPR.

Используя извлеченные тематические модели, мы проанализировали содержание политик конфиденциальности и вручную оценили точность индексации абзацев для набора выбранных политик. В общем случае точность, полученная для набора данных IoT, была немного выше, чем для моделей, извлеченных из OPP-115. Например, для политики конфиденциальности Xiaomi [14] мы получили точность 75\% и 69\% для наборов данных IoT и OPP-115 соответственно. На рисунке 2 показано распределение семантических тематических моделей абзацев в тексте Политики конфиденциальности Xiaomi. Отчетливо видно, что большая часть документа посвящена описанию различных аспектов сбора данных первой стороной – указанию, какие типы данных собираются, есть ли какие-либо варианты выбора/отказа. Полученные результаты также сравнивались с результатами [7] с помощью онлайн-инструмента Pribot [15]. Сравнительный анализ показал, что LDA выявило все основные аспекты использования персональных данных, за исключением одной целевой детской аудитории. Когда мы пересматривали политику, мы посвятили этому аспекту только одно предложение.

\subsection{Подход основанный на применении контекстно-свободных грамматик и синонимическом поиске}

Другой предложенный подход -- подход, основанный на анализе с помощью контекстно-свободных грамматик и синонимического поиска. Синонимический поиск в данном случае -- это подмена ключевых слов и их синонимов метками, например <<\_\_FP\_A\_\_>> означает, что это слово и его синонимы считаются акторами первой стороны. Этот метод можно применить ко многим другим словам. Например, сообщения электронной почты, аватары, местоположение также могут быть объектами и синонимами абстрактной метки <<\_\_CN\_\_>>, которая означает существительное сбора или объект сбора. Так все ключевые слова могут быть преобразованы в их смыслы в контексте предметной области. Маркировка выполняется легко, все слова совпадающие с пулами заменяются метками этих пулов.

Предварительная обработка данных в данном случае состоит из токенизации и лемматизации для более гибкой замены слов на метки их пулов.

При анализе пользовательского согласия сайта недостаточно найти ключевые слова, относящиеся к разным типам персональных данных, например цель и правовую основу распознать гораздо сложнее. Следующий шаг - установить слова отношения в предложениях, чтобы можно было определенно сказать, что ярлыки пулы синонимов связаны друг с другом и формируют логическая цепочку. Один из возможных способов определения отношений слов в тексте на естественном языке -- это синтаксический анализ предложения, основанный на частеречной разметке \cite{POS}. Имея размеченное по частям речи предложение, парсер грамматики NLTK \cite{NLTK} строит деревья предложений по правилам грамматики. Одно из таких деревьев в обозначениях NLTK можно увидеть на рисунке \ref{fig:nltk_tree} \cite{NLTK}, где <<S>> -- основа предложения, <<NP>> -- именная фраза, <<VP>> -- глагольная фраза, <<Adj>> -- прилагательное, <<НОМ>> -- именное словосочетание, <<ПП>> -- предлог фраза, <<Det>> -- артикль, <<V>> -- глагол, <<N>> -- существительное, <<P>> -- предлог.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример грамматического разбора\label{fig:nltk_tree}}}
    {\includegraphics[width=.7\textwidth]{tree.pdf}}
    \vspace{-\baselineskip}
\end{figure}

В предлагаемом подходе немного другая грамматическая запись. Созданная грамматика представлена в (\ref{eq:grammar1}).
\begin{equation}
    \label{eq:grammar1}
    \left\{ 
        \begin{array}{l}
            D \rightarrow S\ |\ S\ D\ |\ S\ \ U\ D\ \\
            S \rightarrow NPG\ \ \ VBG \\
            VPG \rightarrow VP\ |\ VP\ \ VPG\ |\ VP\ \ U\ \ VPG \\
            NPG \rightarrow NP\ |\ NP\ \ NPG\ |\ NP\ \ U\ \ NPG \\
            AJPG \rightarrow AJ\ |\ AJ\ \ APG\ |\ AJ\ \ U\ \ APG \\
            AVPG \rightarrow AV\ |\ AV\ \ APG\ |\ AV\ \ U\ \ APG \\
            VP \rightarrow V APG\ |\ V\ \ PPG\ |\ V\ \ PP\ \ APG \\
            NP \rightarrow NOM\ |\ DET\ \ NOM \\
            NOM \rightarrow N\ |\ AJPG\ \ N \\
            PP \rightarrow NPG\ |\ P\ \ NPG
        \end{array}
    \right.\ ,
\end{equation}
\makebox[12.5mm]{где\hfill}$D$ -- документ,\\
\makebox[12.5mm]{}$SB$ -- синтаксическая основа предложения с его зависимостями,\\
\makebox[12.5mm]{}$U$ -- союз,\\
\makebox[12.5mm]{}$NPG$ -- группа именных фраз,\\
\makebox[12.5mm]{}$VPG$ -- группа глагольных фраз,\\
\makebox[12.5mm]{}$AJPG$ -- группа однородных прилагательных,\\
\makebox[12.5mm]{}$AVPG$ -- группа однородных наречий,\\
\makebox[12.5mm]{}$PPG$ -- группа однородных дополнений,\\
\makebox[12.5mm]{}$VP$ -- глагольная группа,\\
\makebox[12.5mm]{}$NP$ -- именная группа,\\
\makebox[12.5mm]{}$NOM$ -- номинальная группа,\\
\makebox[12.5mm]{}$P$ -- предлог,\\
\makebox[12.5mm]{}$AJ$ -- прилагательное,\\
\makebox[12.5mm]{}$AV$ -- наречие,\\
\makebox[12.5mm]{}$PP$ -- существительное с предлогом,\\
\makebox[12.5mm]{}$N$ -- существительное,\\
\makebox[12.5mm]{}$V$ -- глагол,\\
\makebox[12.5mm]{}$DET$ -- определяющее слово.

 Грамматика из формулы (\ref{eq:grammar1}) позволяет рекурсивно выделять основу предложения и последовательности глагола, существительного, прилагательного, наречия и т.д. Это все еще не идеальное решение, но попытка найти более сложные предложения в политиках безопасности. Этот подход требует использования пулов синонимов, которые соответствуют различным ключевым словам. Поэтому в грамматику включены метки пулов синонимов, привязанных к части речи. Метки пулов вручную назначены частям речи для преобразования привязок частей речи NLTK, это показано в формуле (\ref{eq:grammar2}).
\begin{equation}
    \label{eq:grammar2}
    \left\{ 
        \begin{array}{l}
            U \rightarrow NLTK\_CC \\
            DET \rightarrow NLTK\_DT \\
            AJ \rightarrow NLTK\_JJ \\
            AV \rightarrow NLTK\_RB \\
            N \rightarrow \_\_CN\_\_\ |\ \_\_FP\_A\_\_\ |\ \_\_TP\_A\_\_\ |\ NLTK\_N \\
            V \rightarrow \_\_CV\_\_\ |\ NLTK\_V
        \end{array},
    \right. 
\end{equation}
\makebox[12.5mm]{где\hfill}$NLTK\_CC$ -- соединение NLTK,\\
\makebox[12.5mm]{}$NLTK\_N$ -- все формы существительных NLTK,\\
\makebox[12.5mm]{}$NLTK\_В$ -- все формы глаголов NLTK,\\
\makebox[12.5mm]{}$NLTK\_DET$ -- определители NLTK,\\
\makebox[12.5mm]{}$NLTK\_RB$ -- все формы наречий NLTK,\\
\makebox[12.5mm]{}$\_\_FP\_A\_\_$ -- метка актора-обладателя персональных данных,\\
\makebox[12.5mm]{}$\_\_TP\_A\_\_$ -- третья сторона,\\
\makebox[12.5mm]{}$\_\_CV\_\_$ -- глагол сбора,\\
\makebox[12.5mm]{}$\_\_CN\_\_$ -- существительное сбора.

Теги, начинающиеся с подчеркивания, являются метками пулов синонимов. Синтаксический анализ выполняет библиотека NLTK. На основе предложенной грамматики, описанной (\ref{eq:grammar1}) и (\ref{eq:grammar2}) и разметки лейблами пулов было построено дерево предложения, результат на рисунке \ref{fig:tree}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Дерево грамматического разбора\label{fig:tree}}}
    {\includegraphics[width=.7\textwidth]{labeled_tree.pdf}}
    \vspace{-\baselineskip}
\end{figure}

Когда было построено дерево предложений последовательность меток ключевых слов может быть распознана. В этом случае представленная на рисунке \ref{fig:tree}, последовательность <<\_\_FP\_A\_\_>>, <<\_\_CV\_\_>>, <<\_\_CN\_\_>> хорошо видна. Такие атомарные последовательности, раскрывают значения частей предложения и могут быть объединены в список, после этого весь смысл документов будет описан этим список. Сочетание маркировки ключевых слов и синтаксического анализа дает значения ключевых слов с отношениями между этими словами, определенными в виде древовидных структур. Дерево структура данных более гибкая, чем строка предложения, деревья и особенно поддеревья показывают важные отношения между словами. Запросы к таким структурам могут дать необходимую информацию для построения логических последовательностей действующих лиц, их действий, субъектов этих действий и, наконец, обстоятельств. Предлагаемый подход определенно имеет такие недостатки, как низкая производительность, вручную определенные пулы синонимов и т.д.


В результате апробации алгоритма латентно-семантического анализа было выяснено что для кластеризации экстремально схожих между собой текстов он  подходит не лучшим образом. В связи с этими обстоятельствами было решено обратить внимание на несколько иной подход анализа текста, основанный на контекстно-свободных грамматиках, тегировании по частям речи и синонимическом поиске.

\subsection{Выводы по строгим методам текстового анализа}

Эксперименты показали, что оба рассмотренных метода имеют как преимущества, так и определенные недостатки. Хотя предложенные подходы, оказались противоречивыми, окончательные результаты заслуживают внимания. Подход с латентно-семантическим поиском оказался не слишком эффективным. Однако, подход основанный на грамматическом анализе предложений и синонимическом поиске дал определенные результаты. Хоть он и не является производительным, с его помощью возможно производить выделение логических цепочек из предложений для получения более формального описания политик безопасности нежели их текстовые варианты.

\subsection{Подход основанный на глубоком обучении}
Исходя из проведенных исследований стало понятно, что более предпочтительным вариантом решения задачи будет подход с применением моделей с глубоким обучением. Реализация подобного проекта -- комплексная задача, ее можно разделить на несколько этапов. Сначала необходимо собрать датасет, потом его разметить для обучения модели, далее обучить модель и получить результаты. Однако сбор датасета тоже является непростой задачей. Для того чтобы осуществить сбор датасета необходим инструмент для поиска и скачивания вэб-страниц из сети интернет. Затем необходимо произвести очистку данных, удалить все теги со страниц, чтобы можно было передать текст аннотаторам. Все этапы сбора датасета полагаются на базу данных. Она лишена сложного объектно-реляционного моделирования, так как в ней по сути необходимо только хранить промежуточные результаты обработки текстовых файлов.

\newpage
\section{Проектирование инструментария}

\subsection{Методика сбора}
Планируя решение появившейся задачи важно уделить внимание источникам дынных для сбора, потому что без них невозможно будет продолжать работу. Это важно еще и потому что необходимо будет адоптировать инструмент сбора данных под конкретные веб-ресурсы, так как на каждом из них реализована собственная html-разметка.

Исходя из ориентированности дата сета на умные устройства, логичным выглядит обращение к крупным торговым площадкам, так как они занимаются дистрибьюцией подобных устройств. На сайтах торговых площадок можно осуществлять поиск продукции и получать данные о ней в том числе и производителя продукции. Типовая разметка веб-страниц располагает для получения такой информации, так как существует лишь несколько вариантов наполнения страницы продукции.

Торговые площадки не предоставляют ссылки на официальные сайты производителей. Поэтому необходимо организовать поиск официальных сайтов производителей. Поисковые движки предоставляют API для поиска, однако некоторые из них являются платными, другие выдают совершенно неприемлемые результаты. С другой использование поисковых движков, предназначенных для реальных пользователей, дает наилучшие результаты из возможных, скорее всего это связано с клиентоориентированностью, то есть получая запрос близкий к наименованию бренда с большей вероятностью будет выдана официальная страница производителя в Интернете.

Далее важной задачей является определение какая из ссылок в результате запроса наиболее четко соответствует искомому производителю. Получение официальных веб-сайтов производителей задача на первый взгляд сложная, однако результаты ручной проверки показали, что лучшим вариантом является поисковый запрос с названием производителя «как есть». В таком случае вебсайт производителя оказывается на первой странице результата поискового запроса, а если не оказывается, значит у этой компании его с очень большой вероятностью нет. 

Получив ссылки предполагаемых официальных сайтов, мы получаем доступ к страницам, на которые они ведут. Поиск политики безопасности на уже обнаруженном сайте производителя является тривиальной задачей. Сейчас на абсолютном большинстве сайтов в футере имеется ссылка, названная как “Privacy” или “Privacy Policy”. Футер доступен на любой странице сайта и является частью глобальной навигационной системы сайта, в него вынесена информация, которая пригождается не так часто как, например, информация из верхних баров и меню, однако тем не менее эта информация важна, и помимо ссылок на политику безопасности зачастую содержит контактные данные и прочую организационную информацию.

Таким образом можно получить ссылки на политики безопасности производителей умной продукции. Далее необходимо произвести обработку скачанных политик безопасности.

\subsection{Методика очистки}

Очистка политик безопасности является комплексной задачей. Получив политику безопасности, необходимо вырезать все теги, которые несут в себе динамику, то есть все элементы управления. Такие элементы как всплывающие модальные диалоговые окна тоже не могут содержать текст политики безопасности. Изображения, помещенные на странице, так же не относятся к политике безопасности. Таким образом получается, что большое количество тегов необходимо агрессивно удалять еще до начала анализа страницы, так как они точно не содержат полезной информации.

Далее необходимо применить обработку, которая включала бы в себя преобразование разметки: недопустимые теги должны быть развернуты, определенные комбинации вложенных тегов должны быть заменены на более тривиальные. Также необходимо очистить теги от атрибутов, так как в них не содержится полезной информации или чего-либо способного положительно сказаться на структуре очищенного документа. Затем по всему дереву DOM осуществляется рекурсивный обход с целью слияния тегов, где это возможно, или оборачивания сырых текстов. В ходе данного этапа также производится нормализация пунктуации и настройки отступов текстов, чтобы привести их к читабельному виду. 

После указанных двух этапов очистки, следует заключительный, на котором из тегов извлекается текст, то есть параграфы, представленные в виде одной длинной строки. Это делается, потому что расставленные определенным образом переводы на новую строку могут по тем или иным причинам не подходить, и это будет более гибким решением, потому что где требуется можно применить лайн-врапинг.

\subsection{Методика разметки}
Текст\dots

\subsection{Потенциальные проблемы}
Еще до решения задачи были выделены потенциальные проблемы, способные замедлить процесс разработки и сбора дата сета. Потенциально возможные проблемы при реализации приложений по добного типа следующие:
\begin{enumerate}
    \item блокировка из-за подозрительных заголовков браузера,
    \item блокировка из-за слишком частого обращения с запросами,
    \item как следствие 2-х предыдущих пунктов требование подтвердить, что это не попытка автоматического доступа (ввод капчи).
    \item Невидимые элементы разметки,
    \item динамически формируемые страницы торговых площадок и политик безопасности,
    \item промахи при сборе данных из-за частично некорректных результатов поиска на торговых площадках и в поисковых движках.
\end{enumerate}

Проблемы 1, 2, 3 решаются использованием разных заголовков браузера попеременно. Также отправка запросов ограничена по частоте от 2 до 6 секунд, ограничение выбирается случайным образом. Такие решения позволяют крайне редко попадать под подозрения, потому что в таком случае поведение максимально похоже на поведение реального пользователя, соответственно процент успеха при попытке получить данные с веб-страницы значительно повышается. Стоит отметить, что данные ограничения очень эффективно обходятся за счет использования прокси-серверов, которые позволяют менять ip-адреса. Еще одним важным и эффективным инструментом для является профиль браузера. Он позволяет запускать безголовый браузер с определенной историей использования будь то куки-файлы, история запросов или аутентификация на различных сервисах. Наличие такой предыстории у браузера для некоторых сайтов является доказательством, что он не автоматизирован.

Проблема 4 решается следующим образом. Попав на страницу политики безопасности, можно исполнить код на javascript, который загрузит на страницу библиотеку для работы с деревом DOM и удалит невидимые элементы разметки.

Проблема 5 решается использованием безголового браузера, который полнофункционален с точки зрения воспроизведения контента, так как поддерживает исполнение javascript кода на странице. Таким образом страница будет загружена и динамические элементы будут созданы, после чего можно будет их обработать. Однако на некоторых веб-сайтах для того, чтобы получить ту или иную информацию необходимо заполнить форму. С такими обстоятельствами сложно бороться – разметка всегда различается, но таких случаев крайне мало, поэтому исключение их из рассмотрения будет оправданным.

Проблема 6 может отчасти решиться конкретизацией поискового запроса путем прибавления к названию производителя ключевых слов и продукции, которая им производится. Хотя этот вариант и показал гораздо более качественные результаты нежели чем поиск производителя «как есть», иногда все же попадается шум.

\subsection{Техническое задание <<Инструментарий для сбора датасета>>}

\subsubsection{Основные положения технического задания}

\subsubsection{Скрейпер вэб-страниц}
Скачивание веб-страниц будет производиться инструментом написанным на языке Python, с помощью библиотек можно скачивать страницы анализировать данные с них, переходить по гиперссылкам и много другое. Такой инструмент позволит просматривать и сохранять содержимое страниц в автоматическом режиме без вмешательства пользователя. Таким образом в автоматическом режиме можно сохранить и проанализировать огромное количество текстовой информации.

\subsubsection{Очистка скачанных страниц политик}
Для очистки страниц от кода разметки планируется использовать библиотеку <<html sanitizer>>. Очистка кода необходима для того, чтобы аннотаторы могли максимально сфокусироваться на анализе текста, таким образом получая чистый текст они не будут отвлекаться на не имеющие значения в контексте задачи фрагменты.

\subsubsection{Инструмент разметки датасета}
Инструмент разметки датасета планировалось реализовать с помощью веб-технологий. Серверная часть будет полагаться на приложение, написанное на PHP, которое будет регулировать порядок выдачи текста на аннотирование. Процесс разметки высокодинамичен, поэтому невозможно избежать написания качественной клиентской части приложения на языке javascript. Это позволит сделать работу аннотаторов максимально производительной, в <<одну сессию>>, так как страница не будет перезагружаться, однако все изменения, которые будут вносится, сохранятся.

\subsubsection{Фреймворк глубокого обучения}
Для создания и тренировки модели анализа текста планируется использовать фреймворк машинного обучения <<Keras>>. Он позволяет быстро создавать классификаторы с самыми разными конфигурациями и любых типов.

После того как классификатор будет сконфигурирован останется лишь обучить его на датасете, полученном ранее.

Обученный классификатор будет в состоянии определять различные характеристики политики безопасности и аспекты обращения с данными, что позволит в автоматическом режиме формировать краткие отчеты о безопасности предоставляемого соглашения.

\subsection{Приложение вэб-скрейпер}

\subsubsection{Первичная декомпозиция и планирование}

Начальным этапом решения задачи является первичная декомпозиция, в ее результате выделяются подзадачи различной важности, которые должны быть решены для доведения цикла разработки до конца. В данном случае можно выделить следующие подзадачи:
\begin{enumerate}
    \item определение источника информации о различной IoT-продукции,
    \item отправка поискового запроса,
    \item получение результатов запроса (список IoT-продуктов),
    \item определение производителей IoT-продукции,
    \item поиск официальных сайтов производителей в сети интернет,
    \item поиск раздела <<политика безопасности>> на сайтах производителей,
    \item скачивание политик безопасности,
    \item очистка скачанных веб-документов от лишних элементов разметки,
    \item слияние тегов и оборачивание сырого текста,
    \item нормализация пунктуации и отступов,
    \item извлечение текста из тегов.
\end{enumerate}

Получение списка производителей возможно на электронных торговых площадках, типовая разметка веб-страниц располагает для получения такой информации, так как существует лишь несколько вариантов наполнения страницы продукции.

Получение официальных веб-сайтов производителей задача на первый взгляд сложная, однако результаты ручной проверки показали, что лучшим вариантом является поисковый запрос с названием производителя <<как есть>>. В таком случае веб-сайт производителя оказывается на первой строчке результата поискового запроса, а если не оказывается, значит у этой компании его с очень большой вероятностью нет.

\subsubsection{Структура приложения вэб-скрейпера}
Исходя из результатов декомпозиции, эффективным подходом выглядит представление приложения в виде последовательно выполняющихся подпрограмм так, что входом модуля является результат работы предыдуще\-го модуля, то есть в виде конвейера. Схема организации приложения предста\-влена на рисунке \ref{fig:pipeline}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Схема организации приложения\label{fig:pipeline}}}
    {\includegraphics[width=\textwidth]{pics_pipeline.png}}
    \vspace{-\baselineskip}
\end{figure}

Далее была разработана композиционная модель приложения, на ней присутствуют все необходимые для решения задач модули. Схема представлена на рисунке \ref{fig:composition}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Композиционная модель приложения\label{fig:composition}}}
    {\includegraphics[width=\textwidth]{pics_modules.png}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Средства разработки вэб-скрейпера}
Для реализации приложения были выбраны следующие средства:
\begin{enumerate}
    \item python 3.9,
    \item «безголовый» браузер Firefox,
    \item драйвер для управления «безголовым» браузером «geckodriver»,
    \item библиотека html-sanitizer для очистки скачанных веб-документов. 
\end{enumerate}

Выбор «безголового» браузера обусловлен потребностью в отрисовке страниц, так как на некоторых веб-страницах разметка генерируется с помощью javascript. Это делает невозможным использование простого скачивания, не обходима страница именно с исполненными скриптами, в противном случае будет невозможно получить требуемую информацию. В то же время браузер лишен графического интерфейса, чем снижается потребление вычислитель ных ресурсов. 

Таким образом приложение построено на 4 основных абстракциях.

\begin{enumerate}
    \item Концепция модуля – одна из основополагающих, так как модулем в данном случае выступает любая подпрограмма, участвующая в сборе данных, принимающая входные данные в виде json-файла, и на выходе дающая так же json-файл чтобы следующий в очереди модуль мог отработать. Модули могут быть написаны с нуля, а могут расширять возможности уже существующих посредством механизма наследования. Таким образом можно не переписывая существующий код, а только добавляя новый изменять поведение программы и адаптировать ее под разные задачи сбора данных.
    \item Концепция конвейера – этот элемент поочередно вызывает модули и передает данные из одного модуля в другой. В результате отработки всех модулей поэтапно решается поставленная задача, то есть сбор данных из интернет-источников. Конвейер может быть сконфигурирован, в него могут быть помещены любые модули, реализующие соответствующий интерфейс. Также может быть сконфигурирована последовательность запуска модулей сбора данных.
    \item Концепция поискового движка – данная концепция порождена в связи с необходимостью сделать приложение как можно более гибким. Такой абстрактный элемент позволяет менять используемые поисковые движки, применять к результатам поиска алгоритмы для определения какие результаты удовлетворяют условиям поиска, а какие нет.
    \item Концепция плагина – плагин обеспечивает сбор данных с какой-либо конкретной торговой площадки. Данная концепция использована так же для обеспечения гибкости приложения – для устранения привязки к набору конкретных торговых площадок. Использую механизм наследования можно переопределить поведение плагина для работы с любой другой торговой площадкой. 
\end{enumerate}

На рисунке 2 модуль «main» отвечает за запуск программы, развертывание основных ее частей. Там же происходит инициализация пула процессов для мультипроцессинга затратных задач таких как, например, взаимодействие с «безголовым» браузером. Он так же отвечает за последовательное исполнение подпрограмм элементов конвейера. Он осуществляет прием выходных и передачу входных данных модулей.

Модуль «initialization» производит проверку файловой системы и создает необходимые директории в папке ресурсов.

Модуль «tools» содержит вспомогательные функции, в частности для ввода и вывода данных в формате json. 

Модуль «crawler» отвечает за получение данных с веб-страниц, в нем агрегированы все инструменты для сбора и очистки данных. 

Модуль «plugins» включает в себя набор плагинов, каждый из которых адаптирован для получения требуемой информации с определенного шаблона веб-страничной разметки. Некоторое поведение инкапсулировано в абстрактном плагине для увеличения «reusability» кода. Получая адрес на вход, данный плагин производит скачивание страницы и с помощью набора шаблонов пытается извлечь информацию. Данный модуль записывает полученную с помощью плагинов информацию в json-файл для большей прозрачности и возможности сохранения результатов между запусками приложения, например, для пропуска данного этапа и использования его сохраненных результатов работы. 

Данные полученные с помощью модулей «products», «websites», «policies», «downloader», «sanitizer», «converter» и «efficiency» записывается в json-файлы для большей прозрачности и возможности сохранения результатов между запусками приложения, например, при пропуске какого-либо из этапов и использования его сохраненных результатов работы. Модуль «products» получение производителей IoT-продуктов. Модуль «websites» получение официальных сайтов производителей. Модуль «policies» получение веб-ссылок на политики безопасности. Модуль «downloader» отвечает за скачивание страниц и их сохранение в отведенную для этого директорию. Модуль «sanitizer» отвечает за очистку скачанных веб-страниц от не нужных тегов и ссылок. Модуль «converter» производит перевод политик безопасности из веб-страничного вида в текстовое представление. Модуль «efficiency» производит расчет статистики по дата сету.

Модуль «web» отвечает за взаимодействие с вебсайтами будь то торговые площадки или сайты производителей IoT-продуктов. В нем используется geckodriver для управления «безголовым» браузером. 

Модуль «proxy» содержит инструменты для скачивания и автоматического применения бесплатных прокси-серверов. Однако ввиду ненадежности бесплатных, есть так же возможность задать список выделенных прокси-серверов. 

Для обеспечения наиболее гибкой настройки как можно больше настроек выведено в отдельный конфигурационный файл. В нем задаются:

\begin{enumerate}
    \item параметры для библиотеки html-sanitizer, в частности набор допустимых тегов и допустимых атрибутов;
    \item параметры безголового браузера, в том числе количество повторных попыток при сбоях, появлении каптчи и так далее, набор юзерагентов для перебора, флаги использования кэширования, флаг запуска браузера в режиме без графического интерфейса, флаг использования прокси, пути для логов, а также путь до профиля браузера;
    \item список директорий и файлов, в которые происходит сохранение результатов сбора данных;
    \item количество процессов для одновременного сбора данных на многоядерных конфигурациях.
\end{enumerate}

Для настройки работы заменяемых элементов таких как поисковые движки плагины и модули, предусмотрены отдельные файлы, в которых создаются те или иные конфигурируемые объекты.

Учитывая конвейерную организацию и передачу результатов из модуля в модуль посредством json-файлов, структура дата сета следующая: каждый модуль имеет свой json-файл для записи результатов. По сути результаты – это массив из python-словарей, каждый словарь является своего рода кортежем, эти кортежи обладают избыточностью данных, однако, таким образом достигается максимальная простота формализации данных. Каждый элемент – IoT устройство, обладающее набором информационных полей: идентификатор; ссылка на страницу на торговой площадке; наименование производителя; ключевое слово, по которому было найдено устройство; ссылка на сайт производителя; ссылка на политику безопасности; путь к сохраненной оригинальной страницы политики безопасности; путь к очищенной политике безопасности; путь к текстовой версии политики безопасности; хэш, сгенерированный по тексту политики; блок статистики по структурным элементам, таким как нумерованные и ненумерованные списки, элементы списков, таблицы, параграфы, длина политики в символах. Пример такой разметки можно увидеть на рисунке \ref{fig:tuple}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример кортежа дата сета\label{fig:tuple}}}
    {\includegraphics[width=\textwidth]{tuple.png}}
    \vspace{-\baselineskip}
\end{figure}

В веб-краулере также предусмотрена возможность явного указания адресов для скачивания политик безопасности, для чего предусмотрен отдельный json-файл, содержащий элементы со схожей структурой. В нем можно указывать любые из полей – они будут заполнены соответствующе, а незаполненные поля останутся равными «null». Явно заданные для скачивания политики считываются непосредственно на этапе скачивания, таким образом данные о названии производителя и другие данные которые участвуют в более ранних стадиях сбора несут сугубо справочный характер. Статистические показатели политик безопасности рассчитываются на последнем этапе работы приложения, что означает их перезапись после каждого запуска, при условии, что модуль расчета статистики активен.

\subsection{Инструмент разметки датасета}
Инструмент разметки датасета планировалось реализовать с помощью веб-технологий. Серверная часть будет полагаться на приложение, написанное на PHP, которое будет регулировать порядок выдачи текста на аннотирование. Процесс разметки высокодинамичен, поэтому невозможно избежать написания качественной клиентской части приложения на языке javascript. Это позволит сделать работу аннотаторов максимально производительной, в <<одну сессию>>, так как страница не будет перезагружаться, однако все изменения, которые будут вносится, сохранятся.

\subsubsection{Объектное моделирование приложения}

Объектная модель инструмента представлена на рисунке \ref{fig:object}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Объектная модель\label{fig:object}}}
    {\includegraphics[width=\textwidth]{models_object.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Реляционная модель приложения}

Реляционная модель инструмента представлена на рисунке \ref{fig:relational}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Реляционная модель\label{fig:relational}}}
    {\includegraphics[width=\textwidth]{models_relational.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Проектирование пользовательского интерфейса}

Презентационный прототип интерфейса инструмента представлен на рисунке \ref{fig:proto}.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Презентационный прототип интерфейса\label{fig:proto}}}
    {\includegraphics[width=\textwidth]{models_proto.pdf}}
    \vspace{-\baselineskip}
\end{figure}

\subsubsection{Средства разработки инструмента разметки}

\newpage
\section{Реализация инструментария}

\subsection{Полученные в результате реализации исходные коды}
В соответствии с результатами декомпозиции, выбора средств и проектирования приложение было реализовано. Характеристики полученных классов и функций приведены далее, в таблицах ?-?. Исходные коды представлены в приложении \hyperref[sec:appendix]{А}.

\subsection{Полученный в результате сбора данных дата сет}
Поиск осуществлялся на торговых площадках amazon и walmart, брались результаты поискового запроса по первым 30-ти страницам, по категориям «smart scale», «smart watch», «smart bracelet», «smart lock», «smart bulb», «smart navigation system», «smart alarm clock», «smart thermostat», «smart plug», «smart light switch», «smart tv», «smart speaker», «smart thermometer», «smart air conditioner», «smart video doorbell», «robot vacuum cleaner», «smart air pu\-ri\-fi\-er», «gps tracking device», «tracking sensor», «tracking device», «indoor came\-ra», «outdoor camera», «voice controller». Всего производителей было найдено приблизительно 160. Стоит отметить, что результат является приемлемым, так как многие производители на данной торговой площадке не имеют вы деленного вебсайта, а пользуются услугами amazon, то есть на таких страницах действует политика безопасности amazon, а не производителя. Также стоит отметить, что у некоторых продуктов явно не указан производитель, что    сократило количественно результат поиска.

Всего было проанализировано 57150 моделей умной продукции, из них для 51727 (90,5\%) были определены производители. Всего уникальных производителей было найдено 6161, из них 1419 (23\%) имеют официальную веб-страницу. Проанализировав найденные веб-сайты были собраны 798 политик безопасности, разумеется, среди них имеется определенный процент промахов, если производитель имеет сходство с каким-либо другим более крупным. Из дата сета были исключены политики безопасности, длина которых в символах не превышала 1000. Это объясняется тем, что некоторые производители имеют на своем сайте страницу с политикой безопасности, но по каким-то причинам эта страница не наполнена. Примеры таких случаев приведены на рисунках \ref{fig:not_found1} и \ref{fig:not_found2}. Таким образом полноценных уникальных политик безопасности осталось 592.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример отсутствующей политики\label{fig:not_found1}}}
    {\includegraphics[width=\textwidth]{not_found1.png}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Пример отсутствующей политики\label{fig:not_found2}}}
    {\includegraphics[width=\textwidth]{not_found2.png}}
    \vspace{-\baselineskip}
\end{figure}

Некоторые из производителей, которые не имеют собственного веб-сайта и политика безопасности которых не была найдена, пользуются услугами хостинга интернет-магазина непосредственно на amazon. В таком случае, будучи частью интернет-магазина на них распространяется политика безопасности площадки, на которой они размещают свои предложения, причем политики могут различаться для разных стран. Случаи с использованием отдельных политик безопасности под различные типы устройств не были зафиксированы, хотя такие случаи и существуют, проще прибегнуть к явному заданию адресов политик, нежели чем к попытке автоматизировать процесс сбора, так как остаются непрозрачными способы выявления подобных ситуаций.

На рисунках \ref{fig:paragraph_size} и \ref{fig:policy_size} приведены статистические данные по объемам абзацев политик и самих докумнетов соответственно.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение политик по объему параграфа\label{fig:paragraph_size}}}
    {\includegraphics[width=\textwidth]{paragraph_size.png}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Распределение политик по объему документа\label{fig:policy_size}}}
    {\includegraphics[width=\textwidth]{policy_size.png}}
    \vspace{-\baselineskip}
\end{figure}

Подсчет количества заголовков сложно организовать автоматизированно в связи с большим разнообразием html-разметки. На каждом сайте своя разметка, своя конвенция по нумерованию секций, заголовков, списков. На некоторых сайтах списки и заголовки нумеруются средствами html, на других нумерация проставлена вручную. Все это порождает разношерстность данных, и их обработка становится сложной с точки зрения учета всех возможных вариантов. Поэтому авторы решили прибегнуть к простому подсчету количества строк длиной меньше 100 символов и не содержащих при этом маркеров «{list item}». Такой подход не даст очень точных показателей, но может дать приблизительные значения. На рисунках \ref{fig:structure_stats1} и \ref{fig:structure_stats2} приведена статистика по структурным элементам политик безопасности в двух частях. Здесь изображены детальные распределения структурных элементов для каждой из найденных политик безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика первых 246 политик в IoT дата сете по структурным элементам\label{fig:structure_stats1}}}
    {\includegraphics[width=\textwidth]{structure_stats1.png}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика последних 246 политик в IoT дата сете по структурным элементам\label{fig:structure_stats2}}}
    {\includegraphics[width=\textwidth]{structure_stats2.png}}
    \vspace{-\baselineskip}
\end{figure}

Таким образом можно описать среднестатистическую политику безопасности, которая состоит из 31.5 абзацев, 33 заголовков, 23.6 элементов перечислений, 0.7 нумерованных списков, 4.4 ненумерованных списка, 0.5 таблиц.

Для дополнительного статистического анализа дата сета, он был кластеризован с помощью латентного размещения Дирихле. Как и в [-] для кластеризации политики безопасности были разбиты на абзацы, после чего была проведена предобработка, состоящая из лемматизации и удаления пунктуации и так называемых «стоп слов». В таблице \ref{tab:iot_clusters} приведены результаты моделирования тем в IoT дата сете. В [-] уже была исследована точность латентного размещения Дирихле, его преимущества и недостатки, на основании чего IoT дата сет был проанализирован именно таким способом.  По ним видно, что с помощью такой кластеризации можно выделить различные аспекты политик безопасности.

\begin{longtable}[H]{
    |c
    |>{\setstretch{1}}m{.43\textwidth}
    |>{\setstretch{1}}m{.43\textwidth}|}
    \caption{Тематическое моделирование\label{tab:iot_clusters}}\\\hline
    \endfirsthead
    \caption*{Продолжение таблицы \ref{tab:iot_clusters}}\\\hline
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.44\textwidth}|}{Координаты семантического пространства} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.44\textwidth}|}{Возможные сценарии использования} \\\hline
    \endhead
    \endfoot
    \endlastfoot
    \multicolumn{1}{|c|}{№} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Координаты семантического пространства} & 
    \multicolumn{1}{>{\centering\setstretch{1}}m{.43\textwidth}|}{Возможные сценарии использования} \\\hline
    0 & email, send, promotional, communication, marketing, opt, product, service, message, list & First-party collection, Opt-in, opt-out messages and notifications to end user \\\hline
    1 & party, third, service, information, privacy, website, share, policy, site, advertising & Third parties sharing for marketing purposes \\\hline
    2 & removed, href, hyperref, question, contact, privacy, us, please, policy, comment & Contact information: company \\\hline
    3 & cookie, device, browser, service, address, website, site, collect, information, use & First-party collection: browser and device information \\\hline
    4 & child, age, entering, detection, year, fill, redirected, show, knowingly & Special audience: children \\\hline
    5 & sensor, educational, suggestion, top, acquirer, mailing, employment, job, taking, clickstream & First-party collection: device and service specific information \\\hline
    6 & corporate, automated, storefrontdigest, indefinite, personalization, direction, administrator, token, shop, employed & Other \\\hline
    7 & data, personal, right, request, processing, information, necessary, legal, purpose, law & First-party collection: right to edit, access, with specified (legal) basis of data processing \\\hline
    8 & sponsor, push, reply, default, swiss, desire, becoming, correspondence, calling, representative & Other \\\hline
    9 & asset, service, product, merger, company, item, list, business, another, referral & Third-party sharing in case of company acquisution and merging \\\hline
    10 & erasure, unaffiliated, input, approximate, format, appliance, pref, persistent, canadian, short & Right to erase \\\hline
    11 & address, name, information, account, email, promotion, password, u, collect, contact & First-party collection: personal and account information \\\hline
    12 & security, protect, safety, hosted, secure, violate, property, others, technical, law & Data security \\\hline
    13 & california, state, resident, institution, law, united, ccpa, right, request, country & Special audience: California residents \\\hline
    14 & change, policy, privacy, statement, time, notice, pci, payment, ds, update & Privacy policy changes \\\hline
\end{longtable}

На рисунке 7 приведены результаты кластеризации дата сета. При кластеризации порог аффилиации абзаца политики безопасности был установлен в 0.3, параграф относился к нескольким кластерам, если вероятность аффилиации с ним была больше указанного порога. По графику на рисунке \ref{fig:topics_stats} можно судить, какую часть от общего объема текстов занимают те или иные аспекты политик безопасности.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика аспектов в IoT дата сете\label{fig:topics_stats}}}
    {\includegraphics[width=\textwidth]{topics_stats.png}}
    \vspace{-\baselineskip}
\end{figure}

Как заключение статистического обзора сформированного дата сета на рисунке \ref{fig:topics_stats1} и \ref{fig:topics_stats2} приведено детальное распределение аспектов политик безопасности по каждой конкретной политике. Здесь в виде гистограммы представлены распределения всех 15 аспектов, выделенных алгоритмом LDA. Каждый абзац может относиться к нескольким аспектам с порогом аффилиации 0.3.

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика первых 246 политик в IoT дата сете по аспектам\label{fig:topics_stats1}}}
    {\includegraphics[width=\textwidth]{topics_stats1.png}}
    \vspace{-\baselineskip}
\end{figure}

\begin{figure}[H]
    \centering
    \ffigbox[\FBwidth]
    {\caption{Статистика последних 246 политик в IoT дата сете по аспектам\label{fig:topics_stats2}}}
    {\includegraphics[width=\textwidth]{topics_stats2.png}}
    \vspace{-\baselineskip}
\end{figure}

\subsection{Полученный в результате реализации пользовательский интерфейс инструмента разметки}
Текст\dots

\subsection{Результаты решения поставленной задачи с помощью разработанного инструментария}
В результате работы программы были найдены 65 политик безопасности, разумеется среди них имеется определенный процент промахов, если производитель имеет сходство с каким либо другим более крупным. Поиск осуществлялся по торговой площадке amazon, брались результаты поискового запроса по первым 10-ти страницам, по категориям <<smart scales>>, <<smart watches>>, <<smart locks>> и <<smart bulbs>>. Всего производителей было найдено приблизительно 160. Стоит отметить, что результат является приемлемым, так как многие производители на данной торговой площадке не имеют выделенного веб-сайта, а пользуются услугами amazon, то есть на таких страницах действует политика безопасности amazon, а не производителя. Также стоит отметить что у некоторых продуктов явно не указан производитель, что сократило количественно результат поиска.

\newpage
\section{Составление бизнес-плана по коммерциализации результатов научно-исследовательской работы магистранта}
Текст\dots

\end{document}